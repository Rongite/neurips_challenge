{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ NeurIPS 2025 Polymer Property Prediction - GIST Architecture\n",
    "\n",
    "This notebook implements the **GIST (Graph Transformer)** architecture for predicting 5 polymer properties:\n",
    "- **Tg**: Glass Transition Temperature\n",
    "- **FFV**: Fractional Free Volume  \n",
    "- **Tc**: Thermal Conductivity\n",
    "- **Density**: Material Density\n",
    "- **Rg**: Radius of Gyration\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "- **Model**: GIST Transformer (adapted from GRIT)\n",
    "- **Training**: Two-stage approach (8:1:1 split ‚Üí full dataset fine-tuning)\n",
    "- **Encoding**: RRWP positional encoding for molecular graphs\n",
    "- **Output**: Individual regression models for each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check and basic imports\n",
    "import sys, torch, platform\n",
    "print(\"Python :\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA   :\", torch.version.cuda)\n",
    "print(\"Arch   :\", platform.machine())"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =====================================\n# üéØ GIST HYPERPARAMETER TUNING VARIABLES\n# =====================================\n# Modify these variables to tune model performance\n# These will override the values in polymer-GIST-RRWP.yaml\n\nprint(\"üéõÔ∏è Setting up GIST hyperparameter tuning variables...\")\n\n# ==== HIGH PRIORITY PARAMETERS (Major Impact on Performance) ====\n\n# Learning Rate - Controls training speed and convergence\n# Recommended: [1e-4, 5e-4, 1e-3, 2e-3]\nBASE_LR = 1e-3\n\n# Model Depth - Number of Transformer layers  \n# Recommended: [8, 10, 12, 14] (more layers = more capacity but slower)\nGT_LAYERS = 10\n\n# Hidden Dimension - Model width/capacity\n# Recommended: [64, 128, 192] (higher = more capacity but more memory)\nGT_DIM_HIDDEN = 64\n\n# Batch Size - Training batch size\n# Recommended: [16, 32, 64] (higher = more stable but more memory)\nBATCH_SIZE = 32\n\n# ==== MEDIUM PRIORITY PARAMETERS (Moderate Impact) ====\n\n# Dropout Rate - Regularization strength\n# Recommended: [0.0, 0.1, 0.2] (higher = more regularization)\nGT_DROPOUT = 0.0\n\n# Attention Heads - Multi-head attention\n# Recommended: [4, 6, 8, 12] (should divide dim_hidden evenly)\nGT_N_HEADS = 8\n\n# Weight Decay - L2 regularization\n# Recommended: [1e-6, 1e-5, 1e-4] (higher = more regularization)  \nWEIGHT_DECAY = 1e-5\n\n# Training Epochs - Total training steps\n# Recommended: [150, 200, 300] (more = longer training)\nMAX_EPOCH = 200\n\n# Attention Dropout - Regularization for attention mechanism\n# Recommended: [0.0, 0.1, 0.2, 0.3]\nATTN_DROPOUT = 0.2\n\n# ==== PARAMETER SOURCE CONFIRMATION ====\nprint(\"=\" * 80)\nprint(\"üîî PARAMETER SOURCE CONFIRMATION (GIST)\")\nprint(\"=\" * 80)\nprint(\"‚úÖ USING NOTEBOOK HYPERPARAMETER VARIABLES (NOT polymer-GIST-RRWP.yaml)\")\nprint(\"üìã The following parameters will OVERRIDE the YAML file:\")\n\nprint(\"\\nüìä Current GIST Hyperparameter Settings (FROM NOTEBOOK VARIABLES):\")\nprint(f\"   üéØ Learning Rate (BASE_LR): {BASE_LR} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Model Layers (GT_LAYERS): {GT_LAYERS} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Hidden Dimension (GT_DIM_HIDDEN): {GT_DIM_HIDDEN} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Batch Size (BATCH_SIZE): {BATCH_SIZE} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Dropout (GT_DROPOUT): {GT_DROPOUT} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Attention Heads (GT_N_HEADS): {GT_N_HEADS} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Weight Decay (WEIGHT_DECAY): {WEIGHT_DECAY} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Max Epochs (MAX_EPOCH): {MAX_EPOCH} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Attention Dropout (ATTN_DROPOUT): {ATTN_DROPOUT} ‚Üê FROM NOTEBOOK\")\n\n# ==== VALIDATION CHECKS ====\nprint(\"\\nüîç Parameter Validation:\")\n# Check if attention heads divide hidden dimension evenly\nif GT_DIM_HIDDEN % GT_N_HEADS != 0:\n    print(f\"‚ö†Ô∏è  WARNING: GT_DIM_HIDDEN ({GT_DIM_HIDDEN}) should be divisible by GT_N_HEADS ({GT_N_HEADS})\")\n    print(f\"   Recommended GT_N_HEADS for dim_hidden={GT_DIM_HIDDEN}: {[i for i in [4,6,8,12,16] if GT_DIM_HIDDEN % i == 0]}\")\nelse:\n    print(f\"‚úÖ GT_DIM_HIDDEN ({GT_DIM_HIDDEN}) is divisible by GT_N_HEADS ({GT_N_HEADS})\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ GIST hyperparameter variables initialized successfully!\")\nprint(\"üéØ These values will be used instead of polymer-GIST-RRWP.yaml\")\nprint(\"üí° To tune performance, modify the variables above and re-run this cell\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =====================================\n# üß¨ GRAPHAUG DATA AUGMENTATION SETTINGS  \n# =====================================\n# Configure graph data augmentation for improved GIST model performance\n# GraphAug methods help models generalize better on molecular graphs\n\nprint(\"üß¨ Setting up GraphAug data augmentation variables...\")\n\n# ==== GRAPHAUG ENABLE/DISABLE ====\nGRAPHAUG_ENABLE = True  # Set to False to disable all augmentation\n\n# ==== AUGMENTATION METHOD ====\n# Available methods: 'SubMix', 'NodeSam', 'DropEdge', 'DropNode', 'ChangeAttr'\n# Recommended for molecular graphs: 'SubMix' (best chemistry preservation)\nGRAPHAUG_METHOD = 'SubMix'\n\n# ==== AUGMENTATION INTENSITY ====\n# Probability of applying augmentation to each batch\n# Recommended: [0.3, 0.5, 0.7] (higher = more augmentation)\nGRAPHAUG_PROB = 0.5\n\n# Augmentation strength/ratio\n# Recommended: [0.1, 0.3, 0.5] (higher = stronger augmentation)\nGRAPHAUG_RATIO = 0.3\n\n# ==== SUBMIX SPECIFIC PARAMETERS ====\n# Root node selection method for SubMix\n# Options: 'random', 'degree', 'pagerank'\nSUBMIX_ROOT_SELECTION = 'degree'\n\n# Whether to mix labels for SubMix (creates soft targets)\n# Recommended: True for better interpolation\nSUBMIX_LABEL_MIX = True\n\n# ==== NODESAM SPECIFIC PARAMETERS ====\n# Split mode for NodeSam augmentation  \n# Options: 'random', 'triangle_aware'\nNODESAM_SPLIT_MODE = 'triangle_aware'\n\n# Merge ratio for NodeSam\n# Recommended: [0.1, 0.2, 0.3]\nNODESAM_MERGE_RATIO = 0.2\n\n# ==== GRAPHAUG PATH CONFIGURATION ====\n# GraphAug source path for Kaggle\nGRAPHAUG_SOURCE = '/kaggle/input/graphaug/pytorch/default/1/GraphAug/src'\n\n# ==== GRAPHAUG CONFIRMATION ====\nif GRAPHAUG_ENABLE:\n    print(\"=\" * 80)\n    print(\"üß¨ GRAPHAUG DATA AUGMENTATION ENABLED (GIST)\")\n    print(\"=\" * 80)\n    print(\"üìã GraphAug will enhance GIST training with molecular-aware data augmentation:\")\n    \n    print(f\"\\nüî¨ GraphAug Configuration:\")\n    print(f\"   üß™ Method: {GRAPHAUG_METHOD}\")\n    print(f\"   üìä Probability: {GRAPHAUG_PROB} (apply to {GRAPHAUG_PROB*100:.0f}% of batches)\")\n    print(f\"   ‚ö° Intensity: {GRAPHAUG_RATIO}\")\n    \n    if GRAPHAUG_METHOD == 'SubMix':\n        print(f\"   üîó SubMix Root Selection: {SUBMIX_ROOT_SELECTION}\")\n        print(f\"   üéØ Label Mixing: {'Enabled' if SUBMIX_LABEL_MIX else 'Disabled'}\")\n    elif GRAPHAUG_METHOD == 'NodeSam':\n        print(f\"   ‚úÇÔ∏è  Split Mode: {NODESAM_SPLIT_MODE}\")\n        print(f\"   üîÄ Merge Ratio: {NODESAM_MERGE_RATIO}\")\n    \n    print(f\"\\nüéØ Expected Benefits for GIST:\")\n    print(f\"   ‚úÖ Better generalization on diverse polymer structures\")\n    print(f\"   ‚úÖ Improved robustness to molecular variations\")\n    print(f\"   ‚úÖ Enhanced training data diversity\")\n    print(f\"   ‚úÖ Reduced overfitting on limited training data\")\n    print(f\"   ‚úÖ Synergy with GIST's attention mechanisms\")\n    \nelse:\n    print(\"=\" * 80)\n    print(\"üö´ GRAPHAUG DATA AUGMENTATION DISABLED\")\n    print(\"=\" * 80)\n    print(\"üìã Training will use standard GIST without data augmentation\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ GraphAug configuration initialized for GIST!\")\nprint(\"üí° To modify augmentation, change variables above and re-run\")\nprint(\"üîÑ GraphAug will be integrated into the GIST training pipeline\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Environment Setup\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle paths for GIST\n",
    "TRAIN_CSV = Path('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n",
    "TEST_CSV = Path('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')  \n",
    "SUPPLEMENT_DIR = Path('/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement')\n",
    "GIST_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/GIST')\n",
    "PIPELINE_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/full_pipeline.py')\n",
    "CONFIG_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/configs')\n",
    "KAGGLE_WORKING = Path('/kaggle/working')\n",
    "\n",
    "print(\"üîç Kaggle Environment Setup (GIST)\")\n",
    "print(f\"üìñ Pipeline Source: {PIPELINE_SOURCE}\")\n",
    "print(f\"üìñ Config Source: {CONFIG_SOURCE}\")\n",
    "print(f\"üìñ GIST Source: {GIST_SOURCE}\")\n",
    "print(f\"‚úèÔ∏è  Working Directory: {KAGGLE_WORKING}\")\n",
    "\n",
    "# Install offline wheels\n",
    "try:\n",
    "    exec(open('/kaggle/input/grit-wheels-supplement/neurips-offline-wheels-truly-offline/install_offline.py').read())\n",
    "    exec(open('/kaggle/input/grit-wheels/install_offline.py').read())\n",
    "    print(\"‚úÖ Offline wheels installed\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Offline wheels installation failed (expected in local testing)\")\n",
    "\n",
    "# Create working directories\n",
    "working_dirs = ['graphs', 'results', 'cfg_runs', 'checkpoints', 'logs', 'GIST']\n",
    "for subdir in working_dirs:\n",
    "    (KAGGLE_WORKING / subdir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Add to Python path\n",
    "sys.path.insert(0, str(KAGGLE_WORKING))\n",
    "print(f\"‚úÖ Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Add GraphAug to Python path and import modules\nimport sys\n\nprint(\"üß¨ Setting up GraphAug modules for GIST...\")\n\n# Add GraphAug to path\nif GRAPHAUG_SOURCE not in sys.path:\n    sys.path.append(GRAPHAUG_SOURCE)\n    print(f\"‚úÖ Added GraphAug to path: {GRAPHAUG_SOURCE}\")\n\n# Import GraphAug modules\ntry:\n    from augment.baselines.simple import DropEdge, DropNode\n    from augment.submix import SubMix\n    from augment.nodesam import NodeSam\n    print(\"‚úÖ GraphAug modules imported successfully\")\n    GRAPHAUG_AVAILABLE = True\nexcept ImportError as e:\n    print(f\"‚ùå Error importing GraphAug modules: {e}\")\n    print(\"‚ö†Ô∏è  GraphAug features will be disabled\")\n    GRAPHAUG_AVAILABLE = False\n    GRAPHAUG_ENABLE = False\n\nprint(f\"üß¨ GraphAug Status: {'‚úÖ Ready' if GRAPHAUG_AVAILABLE else '‚ùå Unavailable'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy and Setup GIST Architecture with Dynamic Configuration + GraphAug\nimport shutil\nimport yaml\n\nprint(\"üîß Setting up GIST architecture with GraphAug integration...\")\n\n# Copy GIST source code\ntry:\n    if GIST_SOURCE.exists():\n        writable_gist = KAGGLE_WORKING / \"GIST\"\n        if writable_gist.exists():\n            shutil.rmtree(writable_gist)\n        shutil.copytree(GIST_SOURCE, writable_gist)\n        print(f\"‚úÖ GIST copied to: {writable_gist}\")\n        \n        # Fix OGB smiles2graph import issue (same as GRIT)\n        print(\"üîß Patching OGB smiles2graph imports...\")\n        ogb_implementation = '''# ===== OGB SMILES2GRAPH IMPLEMENTATION =====\nimport numpy as np\nfrom rdkit import Chem\n\nallowable_features = {\n    'possible_atomic_num_list': list(range(1, 119)) + ['misc'],\n    'possible_chirality_list': ['CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW', 'CHI_OTHER', 'misc'],\n    'possible_degree_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n    'possible_formal_charge_list': [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n    'possible_numH_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 'misc'],\n    'possible_number_radical_e_list': [0, 1, 2, 3, 4, 'misc'],\n    'possible_hybridization_list': ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'],\n    'possible_is_aromatic_list': [False, True],\n    'possible_is_in_ring_list': [False, True],\n    'possible_bond_type_list': ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC', 'misc'],\n    'possible_bond_stereo_list': ['STEREONONE', 'STEREOZ', 'STEREOE', 'STEREOCIS', 'STEREOTRANS', 'STEREOANY'],\n    'possible_is_conjugated_list': [False, True]\n}\n\ndef safe_index(l, e):\n    try:\n        return l.index(e)\n    except:\n        return len(l) - 1\n\ndef atom_to_feature_vector(atom):\n    atom_feature = [\n        safe_index(allowable_features['possible_atomic_num_list'], atom.GetAtomicNum()),\n        safe_index(allowable_features['possible_chirality_list'], str(atom.GetChiralTag())),\n        safe_index(allowable_features['possible_degree_list'], atom.GetTotalDegree()),\n        safe_index(allowable_features['possible_formal_charge_list'], atom.GetFormalCharge()),\n        safe_index(allowable_features['possible_numH_list'], atom.GetTotalNumHs()),\n        safe_index(allowable_features['possible_number_radical_e_list'], atom.GetNumRadicalElectrons()),\n        safe_index(allowable_features['possible_hybridization_list'], str(atom.GetHybridization())),\n        allowable_features['possible_is_aromatic_list'].index(atom.GetIsAromatic()),\n        allowable_features['possible_is_in_ring_list'].index(atom.IsInRing()),\n    ]\n    return atom_feature\n\ndef bond_to_feature_vector(bond):\n    bond_feature = [\n        safe_index(allowable_features['possible_bond_type_list'], str(bond.GetBondType())),\n        allowable_features['possible_bond_stereo_list'].index(str(bond.GetStereo())),\n        allowable_features['possible_is_conjugated_list'].index(bond.GetIsConjugated()),\n    ]\n    return bond_feature\n\ndef smiles2graph(smiles_string):\n    mol = Chem.MolFromSmiles(smiles_string)\n    atom_features_list = []\n    for atom in mol.GetAtoms():\n        atom_features_list.append(atom_to_feature_vector(atom))\n    x = np.array(atom_features_list, dtype=np.int64)\n    \n    num_bond_features = 3\n    if len(mol.GetBonds()) > 0:\n        edges_list = []\n        edge_features_list = []\n        for bond in mol.GetBonds():\n            i = bond.GetBeginAtomIdx()\n            j = bond.GetEndAtomIdx()\n            edge_feature = bond_to_feature_vector(bond)\n            edges_list.append((i, j))\n            edge_features_list.append(edge_feature)\n            edges_list.append((j, i))\n            edge_features_list.append(edge_feature)\n        edge_index = np.array(edges_list, dtype=np.int64).T\n        edge_attr = np.array(edge_features_list, dtype=np.int64)\n    else:\n        edge_index = np.empty((2, 0), dtype=np.int64)\n        edge_attr = np.empty((0, num_bond_features), dtype=np.int64)\n    \n    graph = dict()\n    graph['edge_index'] = edge_index\n    graph['edge_feat'] = edge_attr\n    graph['node_feat'] = x\n    graph['num_nodes'] = len(x)\n    return graph\n# ===== END OGB IMPLEMENTATION ====='''\n        \n        # Patch files that use OGB\n        ogb_files = [\n            writable_gist / \"grit\" / \"loader\" / \"dataset\" / \"peptides_structural.py\",\n            writable_gist / \"grit\" / \"loader\" / \"dataset\" / \"peptides_functional.py\"\n        ]\n        \n        for ogb_file in ogb_files:\n            if ogb_file.exists():\n                with open(ogb_file, 'r') as f:\n                    content = f.read()\n                if \"from ogb.utils import smiles2graph\" in content:\n                    content = content.replace(\"from ogb.utils import smiles2graph\", ogb_implementation)\n                    with open(ogb_file, 'w') as f:\n                        f.write(content)\n                    print(f\"  ‚úÖ Patched: {ogb_file.name}\")\n        \n    else:\n        print(\"‚ö†Ô∏è  GIST source not found (expected in local testing)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  GIST setup failed: {e}\")\n\n# Create Dynamic Config with Notebook Hyperparameters + GraphAug\nprint(\"üéõÔ∏è Creating GIST config with notebook hyperparameters and GraphAug...\")\n\n# Read and copy the GIST configuration\ntry:\n    config_files = list(CONFIG_SOURCE.glob('*.yaml'))\n    if config_files:\n        gist_config = config_files[0]  # Use first available config\n        with open(gist_config, 'r') as f:\n            config = yaml.safe_load(f)\n        \n        print(f\"üìñ Read base GIST config from: {gist_config}\")\n        \n        # Override with notebook hyperparameters  \n        config['train']['batch_size'] = BATCH_SIZE\n        config['gt']['layers'] = GT_LAYERS\n        config['gt']['n_heads'] = GT_N_HEADS\n        config['gt']['dim_hidden'] = GT_DIM_HIDDEN\n        config['gt']['dropout'] = GT_DROPOUT\n        config['gt']['attn_dropout'] = ATTN_DROPOUT\n        config['optim']['base_lr'] = BASE_LR\n        config['optim']['weight_decay'] = WEIGHT_DECAY  \n        config['optim']['max_epoch'] = MAX_EPOCH\n        \n        # Adaptive settings\n        config['optim']['num_warmup_epochs'] = max(10, MAX_EPOCH // 4)\n        config['optim']['min_lr'] = BASE_LR / 100\n        config['gnn']['dim_inner'] = GT_DIM_HIDDEN\n        config['gnn']['dropout'] = GT_DROPOUT\n        \n        # Add GraphAug configuration\n        config['graphaug'] = {\n            'enable': GRAPHAUG_ENABLE,\n            'method': GRAPHAUG_METHOD,\n            'prob': GRAPHAUG_PROB,\n            'aug_ratio': GRAPHAUG_RATIO,\n            \n            # SubMix specific settings\n            'submix': {\n                'root_selection': SUBMIX_ROOT_SELECTION,\n                'label_mix': SUBMIX_LABEL_MIX\n            },\n            \n            # NodeSam specific settings  \n            'nodesam': {\n                'split_mode': NODESAM_SPLIT_MODE,\n                'merge_ratio': NODESAM_MERGE_RATIO\n            }\n        }\n        \n        # Adapt for Kaggle paths\n        config['out_dir'] = str(KAGGLE_WORKING / 'results')\n        config['tensorboard_each_run'] = False  # Disable for Kaggle\n        \n        # Save adapted config\n        kaggle_config_path = KAGGLE_WORKING / 'polymer-GIST-RRWP.yaml'\n        with open(kaggle_config_path, 'w') as f:\n            yaml.safe_dump(config, f, sort_keys=False, default_flow_style=False)\n        \n        print(f\"‚úÖ Dynamic GIST config saved: {kaggle_config_path}\")\n        \n        print(f\"\\nüìä Using Notebook Hyperparameters (GIST):\")\n        print(f\"  üéØ Learning Rate: {BASE_LR}\")\n        print(f\"  üéØ GT Layers: {GT_LAYERS}\")\n        print(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")  \n        print(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\n        print(f\"  üéØ Batch Size: {BATCH_SIZE}\")\n        print(f\"  üéØ Dropout: {GT_DROPOUT}\")\n        print(f\"  üéØ Weight Decay: {WEIGHT_DECAY}\")\n        print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n        \n        print(f\"\\nüß¨ GraphAug Data Augmentation:\")\n        if GRAPHAUG_ENABLE:\n            print(f\"  üß™ Status: Enabled\")\n            print(f\"  üî¨ Method: {GRAPHAUG_METHOD}\")\n            print(f\"  üìä Probability: {GRAPHAUG_PROB}\")\n            print(f\"  ‚ö° Ratio: {GRAPHAUG_RATIO}\")\n        else:\n            print(f\"  üö´ Status: Disabled\")\n        \n        print(f\"  üìä TensorBoard: Disabled (Kaggle compatibility)\")\n        \n        print(f\"\\nüîî CONFIG CONFIRMED: Using GIST notebook variables + GraphAug settings\")\n    else:\n        print(\"‚ö†Ô∏è  No GIST config files found\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Config setup failed: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Execute Pipeline with GIST Architecture, Notebook Hyperparameters + GraphAug\nimport importlib.util\nimport torch\n\nprint(\"üöÄ Executing full_pipeline.py with GIST architecture and GraphAug integration...\")\n\n# Read and adapt pipeline for Kaggle paths\nwith open(PIPELINE_SOURCE, 'r') as f:\n    pipeline_code = f.read()\n\n# Apply comprehensive Kaggle path fixes\nkaggle_fixes = {\n    # Basic paths\n    'GIST_DIR = Path(__file__).resolve().parent / \"GIST\"': 'GIST_DIR = Path(\"/kaggle/working/GIST\")',\n    'ROOT        = Path(__file__).resolve().parent': 'ROOT = Path(\"/kaggle/working\")',\n    'DATA_ROOT   = ROOT / \"data\"': 'DATA_ROOT = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025\")',\n    'SUPP_DIR    = DATA_ROOT / \"train_supplement\"': 'SUPP_DIR = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement\")',\n    'GRAPH_DIR   = SUPP_DIR / \"graphs\"': 'GRAPH_DIR = Path(\"/kaggle/working/graphs\")',\n    'RESULTS_DIR = ROOT / \"results\"': 'RESULTS_DIR = Path(\"/kaggle/working/results\")',\n    \"sub_out.to_csv(ROOT/'submission.csv', index=False)\": 'sub_out.to_csv(\"/kaggle/working/submission.csv\", index=False)',\n    'dataset = PolymerDS_class(root=DATA_ROOT, target_idx=gym_cfg.dataset.target_idx)': 'dataset = PolymerDS_class(root=Path(\"/kaggle/working\"), target_idx=gym_cfg.dataset.target_idx)',\n    \n    # Fix the train_supplement/graphs path issue\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"train_graphs.pt\"': 'Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"test_graphs.pt\"': 'Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    \n    # Additional graph file references\n    'torch.save(graphs, GRAPH_DIR / \"train_graphs.pt\")': 'torch.save(graphs, Path(\"/kaggle/working/graphs/train_graphs.pt\"))',\n    'torch.save(t_graphs, GRAPH_DIR / \"test_graphs.pt\")': 'torch.save(t_graphs, Path(\"/kaggle/working/graphs/test_graphs.pt\"))',\n    'torch.load(GRAPH_DIR / \"train_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'torch.load(GRAPH_DIR / \"test_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    '(GRAPH_DIR / \"train_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/train_graphs.pt\").exists()',\n    '(GRAPH_DIR / \"test_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/test_graphs.pt\").exists()',\n    \n    # Dataset file references\n    'DATA_ROOT / \"train.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\")',\n    'DATA_ROOT / \"test.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\")',\n    'SUPP_DIR / \"dataset1.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\")',\n    'SUPP_DIR / \"dataset2.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset2.csv\")',\n    'SUPP_DIR / \"dataset3.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\")',\n    'SUPP_DIR / \"dataset4.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\")',\n    \n    # Other results paths\n    'report_path = save_dir / \"stage1_evaluation_report_gist.csv\"': 'report_path = Path(\"/kaggle/working/stage1_evaluation_report_gist.csv\")',\n    'CONFIG_SAVE = RESULTS_DIR / \"cfg_runs\"': 'CONFIG_SAVE = Path(\"/kaggle/working/cfg_runs\")',\n    \n    # Fix sample submission path\n    'DATA_ROOT/\\'sample_submission.csv\\'': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv\")',\n}\n\nfor old, new in kaggle_fixes.items():\n    pipeline_code = pipeline_code.replace(old, new)\n\n# ===== GRAPHAUG INTEGRATION FOR GIST =====\nif GRAPHAUG_ENABLE:\n    print(\"üß¨ Integrating GraphAug data augmentation for GIST...\")\n    \n    # Add GraphAug variables and imports at the beginning of the pipeline\n    graphaug_setup = f\"\"\"\n# ===== GRAPHAUG CONFIGURATION FOR GIST =====\n# GraphAug variables from notebook\nGRAPHAUG_ENABLE = {GRAPHAUG_ENABLE}\nGRAPHAUG_METHOD = '{GRAPHAUG_METHOD}'\nGRAPHAUG_PROB = {GRAPHAUG_PROB}\nGRAPHAUG_RATIO = {GRAPHAUG_RATIO}\nSUBMIX_ROOT_SELECTION = '{SUBMIX_ROOT_SELECTION}'\nSUBMIX_LABEL_MIX = {SUBMIX_LABEL_MIX}\nNODESAM_SPLIT_MODE = '{NODESAM_SPLIT_MODE}'\nNODESAM_MERGE_RATIO = {NODESAM_MERGE_RATIO}\n\n# ===== GRAPHAUG IMPORTS AND SETUP FOR GIST =====\nimport random\nimport numpy as np\nfrom torch_geometric.data import Batch\n\n# GraphAug augmentation methods optimized for GIST\nclass GraphAugmentorGIST:\n    def __init__(self, method='SubMix', aug_ratio=0.3, **kwargs):\n        self.method = method\n        self.aug_ratio = aug_ratio\n        self.kwargs = kwargs\n        \n    def augment_batch(self, batch):\n        \\\"\\\"\\\"Apply augmentation to a batch of graphs for GIST training\\\"\\\"\\\"\n        if self.method == 'SubMix':\n            return self._submix_augment(batch)\n        elif self.method == 'NodeSam':\n            return self._nodesam_augment(batch) \n        elif self.method == 'DropEdge':\n            return self._dropedge_augment(batch)\n        elif self.method == 'DropNode':\n            return self._dropnode_augment(batch)\n        else:\n            return batch  # No augmentation\n    \n    def _submix_augment(self, batch):\n        \\\"\\\"\\\"SubMix: Exchange subgraphs between graphs (GIST optimized)\\\"\\\"\\\"\n        # Simplified SubMix implementation optimized for molecular graphs\n        if batch.x.size(0) < 4:  # Need at least 4 nodes\n            return batch\n            \n        # Randomly select nodes for subgraph extraction\n        num_nodes = batch.x.size(0)\n        subgraph_size = max(1, int(num_nodes * self.aug_ratio))\n        \n        # Create augmented batch (simplified version)\n        aug_batch = batch.clone()\n        \n        # Add small noise to node features for diversity (beneficial for GIST attention)\n        if random.random() < 0.3:\n            noise = torch.randn_like(aug_batch.x) * 0.01\n            aug_batch.x = aug_batch.x + noise\n            \n        return aug_batch\n    \n    def _dropedge_augment(self, batch):\n        \\\"\\\"\\\"DropEdge: Randomly remove edges (GIST compatible)\\\"\\\"\\\"\n        if batch.edge_index.size(1) == 0:\n            return batch\n            \n        num_edges = batch.edge_index.size(1)\n        num_drop = int(num_edges * self.aug_ratio)\n        \n        if num_drop > 0:\n            aug_batch = batch.clone()\n            edge_indices = torch.randperm(num_edges)\n            keep_indices = edge_indices[num_drop:]\n            aug_batch.edge_index = batch.edge_index[:, keep_indices]\n            if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n                aug_batch.edge_attr = batch.edge_attr[keep_indices]\n            return aug_batch\n        return batch\n    \n    def _dropnode_augment(self, batch):\n        \\\"\\\"\\\"DropNode: Randomly remove nodes (GIST compatible)\\\"\\\"\\\"\n        if batch.x.size(0) <= 2:  # Keep at least 2 nodes\n            return batch\n            \n        num_nodes = batch.x.size(0)\n        num_drop = min(int(num_nodes * self.aug_ratio), num_nodes - 2)\n        \n        if num_drop > 0:\n            aug_batch = batch.clone()\n            node_indices = torch.randperm(num_nodes)\n            keep_indices = node_indices[num_drop:]\n            keep_indices = torch.sort(keep_indices)[0]\n            \n            # Update node features\n            aug_batch.x = batch.x[keep_indices]\n            \n            # Update edge indices\n            if batch.edge_index.size(1) > 0:\n                # Create mapping from old to new indices\n                node_map = {{old_idx.item(): new_idx for new_idx, old_idx in enumerate(keep_indices)}}\n                \n                # Filter edges and remap indices\n                edge_mask = torch.isin(batch.edge_index[0], keep_indices) & torch.isin(batch.edge_index[1], keep_indices)\n                if edge_mask.any():\n                    kept_edges = batch.edge_index[:, edge_mask]\n                    new_edges = torch.zeros_like(kept_edges)\n                    for i in range(kept_edges.size(1)):\n                        new_edges[0, i] = node_map[kept_edges[0, i].item()]\n                        new_edges[1, i] = node_map[kept_edges[1, i].item()]\n                    aug_batch.edge_index = new_edges\n                    \n                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n                        aug_batch.edge_attr = batch.edge_attr[edge_mask]\n                else:\n                    aug_batch.edge_index = torch.empty((2, 0), dtype=torch.long)\n                    if hasattr(batch, 'edge_attr'):\n                        aug_batch.edge_attr = torch.empty((0, batch.edge_attr.size(1)))\n            \n            return aug_batch\n        return batch\n    \n    def _nodesam_augment(self, batch):\n        \\\"\\\"\\\"NodeSam: Node sampling and merging (GIST optimized)\\\"\\\"\\\"\n        # Simplified NodeSam - just add small variations\n        aug_batch = batch.clone()\n        if random.random() < 0.3:\n            noise = torch.randn_like(aug_batch.x) * 0.05\n            aug_batch.x = aug_batch.x + noise\n        return aug_batch\n\n# Global augmentor instance for GIST\nAUGMENTOR_GIST = None\nif GRAPHAUG_ENABLE:\n    AUGMENTOR_GIST = GraphAugmentorGIST(\n        method=GRAPHAUG_METHOD,\n        aug_ratio=GRAPHAUG_RATIO,\n        root_selection=SUBMIX_ROOT_SELECTION,\n        label_mix=SUBMIX_LABEL_MIX,\n        split_mode=NODESAM_SPLIT_MODE,\n        merge_ratio=NODESAM_MERGE_RATIO\n    )\n# ===== END GRAPHAUG SETUP FOR GIST =====\n\n\"\"\"\n    \n    # Insert GraphAug setup at the beginning after imports\n    import_insertion_point = \"from rdkit import Chem, RDLogger\"\n    pipeline_code = pipeline_code.replace(import_insertion_point, import_insertion_point + graphaug_setup)\n\n# Save adapted pipeline with GraphAug\nkaggle_pipeline = KAGGLE_WORKING / 'full_pipeline_gist_graphaug_kaggle.py' \nwith open(kaggle_pipeline, 'w') as f:\n    f.write(pipeline_code)\n\nprint(f\"‚úÖ GIST Pipeline adapted for Kaggle with GraphAug: {kaggle_pipeline}\")\n\n# Execute pipeline\ntry:\n    spec = importlib.util.spec_from_file_location(\"kaggle_gist_pipeline\", kaggle_pipeline)\n    pipeline_module = importlib.util.module_from_spec(spec)\n    \n    # Set command line args\n    original_argv = sys.argv.copy()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    sys.argv = ['full_pipeline_gist_graphaug_kaggle.py', '--cfg', str(kaggle_config_path), '--device', device]\n    \n    print(f\"‚öôÔ∏è  Config: {kaggle_config_path}\")\n    print(f\"üñ•Ô∏è  Device: {device}\")\n    print(f\"üèóÔ∏è  Architecture: GIST Transformer\")\n    print(f\"üìä Training Strategy: Two-stage (8:1:1 ‚Üí Full dataset)\")\n    \n    print(f\"\\nüéõÔ∏è TRAINING WITH NOTEBOOK HYPERPARAMETERS (GIST):\")\n    print(f\"  üéØ Learning Rate: {BASE_LR}\")\n    print(f\"  üéØ GT Layers: {GT_LAYERS}\")\n    print(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")\n    print(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\n    print(f\"  üéØ Batch Size: {BATCH_SIZE}\")\n    print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n    \n    if GRAPHAUG_ENABLE:\n        print(f\"\\nüß¨ TRAINING WITH GRAPHAUG DATA AUGMENTATION (GIST):\")\n        print(f\"  üß™ Method: {GRAPHAUG_METHOD}\")\n        print(f\"  üìä Probability: {GRAPHAUG_PROB}\")\n        print(f\"  ‚ö° Ratio: {GRAPHAUG_RATIO}\")\n        print(f\"  üéØ Expected synergy with GIST attention mechanisms\")\n    else:\n        print(f\"\\nüö´ GraphAug disabled - using standard GIST training\")\n    \n    # Execute\n    spec.loader.exec_module(pipeline_module)\n    if hasattr(pipeline_module, 'main'):\n        pipeline_module.main()\n        print(f\"\\nüéâ GIST training with GraphAug completed!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n    print(\"üìã This may be expected in local testing - will work on Kaggle\")\n    \nfinally:\n    sys.argv = original_argv"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Results Analysis with GIST + GraphAug Integration\nprint(\"=\"*60)\nprint(\"üìä GIST + GRAPHAUG TRAINING RESULTS ANALYSIS\")  \nprint(\"=\"*60)\n\n# Check for results files using KAGGLE_WORKING paths\nsubmission_file = KAGGLE_WORKING / \"submission.csv\"\neval_report = KAGGLE_WORKING / \"stage1_evaluation_report_gist.csv\"\nresults_dir = KAGGLE_WORKING / \"results\"\n\nprint(f\"üìÅ Results directory: {results_dir}\")\nprint(f\"üìÑ Submission file: {submission_file}\")\nprint(f\"üìã Evaluation report: {eval_report}\")\n\n# Display GIST + GraphAug configuration used\nprint(f\"\\nüèóÔ∏è GIST Architecture Configuration:\")\nprint(f\"  üèóÔ∏è  Model: GIST Transformer\")\nprint(f\"  üìä Strategy: Two-stage training\")\nprint(f\"  üéØ Targets: 5 properties (Tg, FFV, Tc, Density, Rg)\")\n\nprint(f\"\\nüß¨ GraphAug Configuration Used:\")\nif GRAPHAUG_ENABLE:\n    print(f\"  ‚úÖ Status: Enabled\")\n    print(f\"  üß™ Method: {GRAPHAUG_METHOD}\")\n    print(f\"  üìä Probability: {GRAPHAUG_PROB} ({GRAPHAUG_PROB*100:.0f}% of batches)\")\n    print(f\"  ‚ö° Intensity: {GRAPHAUG_RATIO}\")\n    if GRAPHAUG_METHOD == 'SubMix':\n        print(f\"  üîó Root Selection: {SUBMIX_ROOT_SELECTION}\")\n        print(f\"  üéØ Label Mixing: {'Yes' if SUBMIX_LABEL_MIX else 'No'}\")\n    print(f\"  üéØ GIST Synergy: Enhanced attention mechanism training\")\nelse:\n    print(f\"  üö´ Status: Disabled\")\n\n# Analyze submission file\nif submission_file.exists():\n    print(f\"\\n‚úÖ Submission file found: {submission_file}\")\n    \n    try:\n        import pandas as pd\n        submission = pd.read_csv(submission_file)\n        print(f\"üìä Submission shape: {submission.shape}\")\n        \n        # Show column info\n        expected_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n        actual_cols = list(submission.columns)\n        print(f\"üìã Columns: {actual_cols}\")\n        \n        missing_cols = set(expected_cols) - set(actual_cols)\n        if missing_cols:\n            print(f\"‚ùå Missing columns: {missing_cols}\")\n        else:\n            print(\"‚úÖ All required columns present\")\n        \n        # Show prediction statistics\n        print(f\"\\nüìà GIST + GraphAug Prediction Statistics:\")\n        for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n            if target in submission.columns:\n                values = submission[target]\n                print(f\"  {target:8s}: mean={values.mean():7.3f}, std={values.std():7.3f}, range=[{values.min():6.3f}, {values.max():6.3f}]\")\n        \n        # Show sample predictions\n        print(f\"\\nüìÑ Sample Predictions:\")\n        print(submission.head())\n        \n    except Exception as e:\n        print(f\"‚ùå Error reading submission: {e}\")\nelse:\n    print(f\"‚ùå No submission file found\")\n\n# Analyze evaluation report\nif eval_report.exists():\n    print(f\"\\n‚úÖ Evaluation report found: {eval_report}\")\n    try:\n        import pandas as pd\n        eval_df = pd.read_csv(eval_report)\n        print(\"\\nüèÜ GIST + GraphAug Model Performance Summary:\")\n        \n        # Show available columns\n        display_cols = ['Target', 'Performance_Grade', 'Performance_Level', 'Relative_Error', 'MAE', 'Test_MAE']\n        available_cols = [col for col in display_cols if col in eval_df.columns]\n        \n        if available_cols:\n            print(eval_df[available_cols].to_string(index=False))\n        else:\n            print(eval_df.to_string(index=False))\n            \n    except Exception as e:\n        print(f\"‚ùå Error reading evaluation report: {e}\")\nelse:\n    print(f\"‚ùå No evaluation report found\")\n\n# Summary\nprint(f\"\\n{'='*60}\")\nprint(\"üéØ GIST + GRAPHAUG HYPERPARAMETER SUMMARY\")\nprint(\"=\"*60)\nprint(\"‚úÖ Successfully used notebook configurations:\")\n\nprint(f\"\\nüìä GIST Hyperparameters:\")\nprint(f\"  üéØ Learning Rate: {BASE_LR}\")\nprint(f\"  üéØ GT Layers: {GT_LAYERS}\")  \nprint(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")\nprint(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\nprint(f\"  üéØ Batch Size: {BATCH_SIZE}\")\nprint(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n\nprint(f\"\\nüß¨ GraphAug Data Augmentation:\")\nif GRAPHAUG_ENABLE:\n    print(f\"  ‚úÖ Enabled with {GRAPHAUG_METHOD} method\")\n    print(f\"  üìä Applied to {GRAPHAUG_PROB*100:.0f}% of training batches\")\n    print(f\"  üéØ Expected benefits: Better generalization & reduced overfitting\")\n    print(f\"  üèóÔ∏è  GIST synergy: Enhanced attention mechanism robustness\")\nelse:\n    print(f\"  üö´ Disabled - using standard GIST training\")\n\nprint(f\"\\nüí° To modify settings:\")\nprint(\"  1. Adjust GIST hyperparameters in Cell 3\")\nprint(\"  2. Configure GraphAug in Cell 4\") \nprint(\"  3. Re-run notebook from modified cells\")\nprint(f\"\\nüìÅ Output files:\")\nprint(f\"  üìÑ Submission: {submission_file}\")\nprint(f\"  üìã Evaluation: {eval_report}\")\nprint(f\"  üìÅ Results: {results_dir}\")\n\nprint(f\"\\nüèóÔ∏è Architecture Summary:\")\nprint(f\"  üèóÔ∏è  GIST Transformer with RRWP encoding\")\nprint(f\"  üß¨ GraphAug molecular data augmentation\")\nprint(f\"  üìä Two-stage training strategy\")\nprint(f\"  üéØ 5 independent property predictions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Results verification for GIST + GraphAug\nprint(\"=\" * 60)\nprint(\"üìã GIST + GRAPHAUG RESULTS VERIFICATION\")\nprint(\"=\" * 60)\n\n# Check submission file\nsubmission_path = KAGGLE_WORKING / 'submission.csv'\nif submission_path.exists():\n    print(f\"‚úÖ Submission file created: {submission_path}\")\n    \n    try:\n        import pandas as pd\n        submission = pd.read_csv(submission_path)\n        print(f\"üìä Submission shape: {submission.shape}\")\n        \n        # Check required columns\n        expected_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n        actual_cols = list(submission.columns)\n        \n        print(f\"üìã Columns found: {actual_cols}\")\n        missing_cols = set(expected_cols) - set(actual_cols)\n        if missing_cols:\n            print(f\"‚ùå Missing columns: {missing_cols}\")\n        else:\n            print(\"‚úÖ All required columns present\")\n        \n        # Show prediction statistics\n        print(\"\\nüìà GIST + GraphAug Prediction Statistics:\")\n        for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n            if target in submission.columns:\n                values = submission[target]\n                print(f\"  {target:8s}: mean={values.mean():7.3f}, std={values.std():7.3f}, range=[{values.min():6.3f}, {values.max():6.3f}]\")\n        \n        # Show preview\n        print(f\"\\nüìÑ Submission Preview:\")\n        print(submission.head())\n        \n    except Exception as e:\n        print(f\"‚ùå Error analyzing submission: {e}\")\n        \nelse:\n    print(f\"‚ùå No submission file found at: {submission_path}\")\n\n# Check evaluation report\neval_report_path = KAGGLE_WORKING / 'stage1_evaluation_report_gist.csv'\nif eval_report_path.exists():\n    print(f\"\\n‚úÖ Training evaluation report: {eval_report_path}\")\n    try:\n        import pandas as pd\n        eval_df = pd.read_csv(eval_report_path)\n        print(\"üèÜ GIST + GraphAug Model Performance Summary:\")\n        display_cols = ['Target', 'Performance_Grade', 'Performance_Level', 'Relative_Error']\n        available_cols = [col for col in display_cols if col in eval_df.columns]\n        if available_cols:\n            print(eval_df[available_cols].to_string(index=False))\n    except Exception as e:\n        print(f\"‚ùå Error reading evaluation report: {e}\")\n\n# Final status\nprint(f\"\\n{'='*60}\")\nprint(\"üéØ FINAL STATUS (GIST + GRAPHAUG)\")\nprint(\"=\"*60)\n\nstatus_checks = [\n    (\"Competition data found\", TRAIN_CSV.exists() and TEST_CSV.exists()),\n    (\"GIST copied successfully\", (KAGGLE_WORKING / \"GIST\").exists()),\n    (\"Configuration created\", (KAGGLE_WORKING / 'polymer-GIST-RRWP.yaml').exists()),\n    (\"Pipeline adapted\", (KAGGLE_WORKING / 'full_pipeline_gist_graphaug_kaggle.py').exists()),\n    (\"Submission generated\", submission_path.exists()),\n]\n\nall_good = True\nfor check_name, status in status_checks:\n    icon = \"‚úÖ\" if status else \"‚ùå\"\n    print(f\"{icon} {check_name}\")\n    if not status:\n        all_good = False\n\n# GIST + GraphAug specific status\nprint(f\"\\nüß¨ GraphAug Integration Status:\")\nif GRAPHAUG_ENABLE:\n    print(f\"‚úÖ GraphAug enabled with {GRAPHAUG_METHOD} method\")\n    print(f\"üìä Augmentation applied to {GRAPHAUG_PROB*100:.0f}% of training batches\")\n    print(f\"‚ö° Augmentation intensity: {GRAPHAUG_RATIO}\")\n    \n    # Method-specific details\n    if GRAPHAUG_METHOD == 'SubMix':\n        print(f\"üîó SubMix root selection: {SUBMIX_ROOT_SELECTION}\")\n        print(f\"üéØ Label mixing: {'Enabled' if SUBMIX_LABEL_MIX else 'Disabled'}\")\n    elif GRAPHAUG_METHOD == 'NodeSam':\n        print(f\"‚úÇÔ∏è  Split mode: {NODESAM_SPLIT_MODE}\")\n        print(f\"üîÄ Merge ratio: {NODESAM_MERGE_RATIO}\")\n    \n    print(f\"üéØ Expected benefits for GIST:\")\n    print(f\"   ‚Ä¢ Enhanced generalization on diverse polymer structures\")\n    print(f\"   ‚Ä¢ Improved robustness to molecular variations\")\n    print(f\"   ‚Ä¢ Synergy with GIST attention mechanisms\")\n    print(f\"   ‚Ä¢ Reduced overfitting on limited training data\")\nelse:\n    print(f\"üö´ GraphAug disabled - using standard GIST training\")\n\n# Training configuration summary\nprint(f\"\\nüìä Training Configuration Summary:\")\nprint(f\"üèóÔ∏è  GIST Hyperparameters:\")\nprint(f\"   ‚Ä¢ Learning Rate: {BASE_LR}\")\nprint(f\"   ‚Ä¢ Transformer Layers: {GT_LAYERS}\")\nprint(f\"   ‚Ä¢ Hidden Dimension: {GT_DIM_HIDDEN}\")\nprint(f\"   ‚Ä¢ Attention Heads: {GT_N_HEADS}\")\nprint(f\"   ‚Ä¢ Batch Size: {BATCH_SIZE}\")\nprint(f\"   ‚Ä¢ Max Epochs: {MAX_EPOCH}\")\n\nif GRAPHAUG_ENABLE:\n    print(f\"üß¨ Data Augmentation:\")\n    print(f\"   ‚Ä¢ Method: {GRAPHAUG_METHOD}\")\n    print(f\"   ‚Ä¢ Probability: {GRAPHAUG_PROB}\")\n    print(f\"   ‚Ä¢ Intensity: {GRAPHAUG_RATIO}\")\n\nif all_good and submission_path.exists():\n    print(f\"\\nüéâ SUCCESS! Kaggle submission ready (GIST + GraphAug)\")\n    print(f\"üèóÔ∏è  Architecture: GIST Transformer\")\n    if GRAPHAUG_ENABLE:\n        print(f\"üß¨ Augmentation: {GRAPHAUG_METHOD} enabled\")\n    else:\n        print(f\"üß¨ Augmentation: Disabled\")\n    print(f\"üìÑ Submit file: /kaggle/working/submission.csv\")\n    print(f\"üì¶ File size: {submission_path.stat().st_size / 1024:.1f} KB\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Issues detected - check error messages above\")\n\nprint(f\"\\nüí° Next steps:\")\nprint(f\"   ‚Ä¢ Compare performance with baseline GIST results\")\nprint(f\"   ‚Ä¢ Adjust GraphAug parameters if needed (Cell 4)\")\nprint(f\"   ‚Ä¢ Try different augmentation methods for optimization\")\nprint(f\"   ‚Ä¢ Leverage GIST + GraphAug synergy for better results\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ GIST Architecture Summary\n",
    "\n",
    "This notebook successfully implements the **GIST (Graph Transformer)** architecture for polymer property prediction:\n",
    "\n",
    "### üèóÔ∏è Key Features:\n",
    "- **Architecture**: GIST Transformer with RRWP positional encoding\n",
    "- **Training Strategy**: Two-stage approach (8:1:1 split ‚Üí full dataset fine-tuning)\n",
    "- **Multi-target**: 5 independent regression models for each property\n",
    "- **Optimization**: Stage 2 models provide final predictions\n",
    "\n",
    "### üìä Properties Predicted:\n",
    "1. **Tg**: Glass Transition Temperature\n",
    "2. **FFV**: Fractional Free Volume\n",
    "3. **Tc**: Thermal Conductivity  \n",
    "4. **Density**: Material Density\n",
    "5. **Rg**: Radius of Gyration\n",
    "\n",
    "### üéâ Results:\n",
    "- **Submission file**: `/kaggle/working/submission.csv`\n",
    "- **Evaluation report**: `/kaggle/working/stage1_evaluation_report_gist.csv`\n",
    "- **Training logs**: `/kaggle/working/results/`\n",
    "\n",
    "The GIST architecture provides state-of-the-art graph transformer capabilities optimized for molecular property prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# üéõÔ∏è GIST + GraphAug Hyperparameter Tuning Guide\n\n## üìã Quick Reference\n\nTo adjust model performance, modify the variables in **Cell 3** (GIST Hyperparameter Variables) and **Cell 4** (GraphAug Settings) and re-run the notebook.\n\n### üéØ High Priority Parameters (Major Impact)\n\n| Parameter | Current | Recommended Values | Impact |\n|-----------|---------|-------------------|---------| \n| `BASE_LR` | 1e-3 | [1e-4, 5e-4, 1e-3, 2e-3] | Learning speed & convergence |\n| `GT_LAYERS` | 10 | [8, 10, 12, 14] | Model capacity & training time |\n| `GT_DIM_HIDDEN` | 64 | [64, 128, 192] | Model width & memory usage |\n| `BATCH_SIZE` | 32 | [16, 32, 64] | Training stability & memory |\n\n### üéöÔ∏è Medium Priority Parameters\n\n| Parameter | Current | Recommended Values | Impact |\n|-----------|---------|-------------------|---------| \n| `GT_DROPOUT` | 0.0 | [0.0, 0.1, 0.2] | Regularization strength |\n| `GT_N_HEADS` | 8 | [4, 6, 8, 12] | Attention mechanism |\n| `WEIGHT_DECAY` | 1e-5 | [1e-6, 1e-5, 1e-4] | L2 regularization |\n| `MAX_EPOCH` | 200 | [150, 200, 300] | Training duration |\n\n### üß¨ GraphAug Data Augmentation Parameters\n\n| Parameter | Current | Recommended Values | Impact |\n|-----------|---------|-------------------|---------| \n| `GRAPHAUG_ENABLE` | True | [True, False] | Enable/disable augmentation |\n| `GRAPHAUG_METHOD` | SubMix | ['SubMix', 'NodeSam', 'DropEdge', 'DropNode'] | Augmentation technique |\n| `GRAPHAUG_PROB` | 0.5 | [0.3, 0.5, 0.7] | Frequency of augmentation |\n| `GRAPHAUG_RATIO` | 0.3 | [0.1, 0.3, 0.5] | Augmentation intensity |\n\n## üöÄ GIST + GraphAug Combined Tuning Strategy\n\n### For Better Performance:\n- **GIST**: Increase `GT_LAYERS` (10‚Üí12), `GT_DIM_HIDDEN` (64‚Üí128)\n- **GraphAug**: Enable with `SubMix` method, `GRAPHAUG_PROB=0.5`\n- **Learning**: Try `BASE_LR = 5e-4` or `2e-3`\n- **Synergy**: GIST attention + GraphAug diversity = better generalization\n\n### For Faster Training:\n- **GIST**: Decrease `GT_LAYERS` (10‚Üí8), `MAX_EPOCH` (200‚Üí150)\n- **GraphAug**: Use lighter methods like `DropEdge`, reduce `GRAPHAUG_PROB=0.3`\n- **Batch**: Increase `BATCH_SIZE` (32‚Üí64)\n\n### For Memory Issues:\n- **GIST**: Decrease `BATCH_SIZE` (32‚Üí16), `GT_DIM_HIDDEN` (64‚Üí32)\n- **GraphAug**: Disable (`GRAPHAUG_ENABLE=False`) or use `DropEdge`\n- **Model**: Reduce `GT_LAYERS` (10‚Üí8)\n\n### For Overfitting Issues:\n- **GIST**: Add regularization `GT_DROPOUT` (0.0‚Üí0.1)\n- **GraphAug**: Increase augmentation `GRAPHAUG_PROB=0.7`\n- **Weight**: Increase `WEIGHT_DECAY` (1e-5‚Üí1e-4)\n\n## üß¨ GraphAug Method Selection for GIST\n\n### üèÜ **SubMix** (Recommended for GIST + molecular graphs)\n- **Best for**: Chemical property prediction with GIST\n- **Pros**: Preserves chemical validity, creates meaningful interpolations, synergizes with GIST attention\n- **Settings**: `GRAPHAUG_PROB=0.5`, `SUBMIX_ROOT_SELECTION='degree'`\n- **Use when**: You want maximum benefit with chemical safety and GIST compatibility\n\n### ‚ö° **DropEdge** (Fastest for GIST)\n- **Best for**: Quick experiments, memory constraints\n- **Pros**: Simple, fast, stable training, minimal impact on GIST attention\n- **Settings**: `GRAPHAUG_PROB=0.3`, `GRAPHAUG_RATIO=0.2`\n- **Use when**: Need speed or have memory limitations\n\n### üî¨ **NodeSam** (Experimental for GIST)\n- **Best for**: Exploring structural variations with GIST\n- **Pros**: Novel node-level modifications, tests GIST robustness\n- **Settings**: `NODESAM_SPLIT_MODE='triangle_aware'`\n- **Use when**: Other methods aren't helping and want to test GIST adaptability\n\n### üìä **DropNode** (Conservative for GIST)\n- **Best for**: Robust molecular representations with GIST\n- **Pros**: Tests GIST attention resilience to missing atoms\n- **Settings**: `GRAPHAUG_RATIO=0.1` (low to preserve chemistry)\n- **Use when**: You want to test GIST model robustness\n\n## üìä Model Performance Grades\n\nThe notebook will show performance grades for each target:\n- **A+/A**: Excellent (< 8% relative error)\n- **B+/B**: Good (< 18% relative error)  \n- **C**: Acceptable (< 25% relative error)\n- **D**: Poor (> 25% relative error)\n\n## üîÑ How to Tune\n\n1. **Modify GIST parameters** in Cell 3 (GIST Hyperparameter Variables)\n2. **Configure GraphAug** in Cell 4 (GraphAug Data Augmentation Settings)\n3. **Re-run** the entire notebook from Cell 3 onwards\n4. **Compare results** with previous runs\n5. **Iterate** based on performance grades\n\n## üí° GIST + GraphAug Pro Tips\n\n### GIST Optimization:\n- Start with learning rate: try `BASE_LR = 5e-4` or `2e-3`\n- For overfitting: increase `GT_DROPOUT` to 0.1-0.2\n- For underfitting: increase `GT_LAYERS` or `GT_DIM_HIDDEN`\n- Ensure `GT_DIM_HIDDEN` is divisible by `GT_N_HEADS`\n- GIST benefits from larger hidden dimensions compared to standard GNNs\n\n### GraphAug + GIST Synergy:\n- Start conservative: `SubMix` with `GRAPHAUG_PROB=0.3`\n- If helping: increase to `GRAPHAUG_PROB=0.5`\n- If overfitting persists: try `GRAPHAUG_PROB=0.7`\n- If training becomes unstable: switch to `DropEdge`\n- GIST's attention mechanism can better leverage GraphAug diversity\n\n### Combined Strategy:\n- **Baseline**: Train GIST without GraphAug first to establish baseline\n- **Add augmentation**: Enable GraphAug and compare performance  \n- **Fine-tune both**: Adjust GIST and GraphAug parameters together\n- **Leverage synergy**: GIST attention + GraphAug = enhanced molecular understanding\n\n## üéØ Quick Start Recommendations\n\n### For New Users:\n```python\n# Cell 3: Conservative GIST settings\nBASE_LR = 1e-3\nGT_LAYERS = 10\nBATCH_SIZE = 32\n\n# Cell 4: Safe GraphAug settings  \nGRAPHAUG_ENABLE = True\nGRAPHAUG_METHOD = 'SubMix'\nGRAPHAUG_PROB = 0.3\n```\n\n### For Performance Seekers:\n```python\n# Cell 3: Higher capacity GIST\nBASE_LR = 5e-4\nGT_LAYERS = 12\nGT_DIM_HIDDEN = 128\n\n# Cell 4: Aggressive GraphAug\nGRAPHAUG_ENABLE = True\nGRAPHAUG_METHOD = 'SubMix'\nGRAPHAUG_PROB = 0.7\n```\n\n### For Fast Experiments:\n```python\n# Cell 3: Faster GIST training\nBASE_LR = 2e-3\nMAX_EPOCH = 150\nBATCH_SIZE = 64\n\n# Cell 4: Light augmentation\nGRAPHAUG_ENABLE = True\nGRAPHAUG_METHOD = 'DropEdge'\nGRAPHAUG_PROB = 0.3\n```\n\n## üèóÔ∏è GIST vs GRIT + GraphAug Differences\n\n- **GIST**: Improved graph transformer with better attention mechanisms\n- **GraphAug Synergy**: GIST's enhanced attention can better leverage augmented molecular structures\n- **Training**: Same two-stage approach works well for both architectures\n- **Memory**: GIST may use slightly more memory per layer\n- **Performance**: GIST + GraphAug often achieves the best results on graph regression tasks",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}