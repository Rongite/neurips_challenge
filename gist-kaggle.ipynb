{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ NeurIPS 2025 Polymer Property Prediction - GIST Architecture\n",
    "\n",
    "This notebook implements the **GIST (Graph Transformer)** architecture for predicting 5 polymer properties:\n",
    "- **Tg**: Glass Transition Temperature\n",
    "- **FFV**: Fractional Free Volume  \n",
    "- **Tc**: Thermal Conductivity\n",
    "- **Density**: Material Density\n",
    "- **Rg**: Radius of Gyration\n",
    "\n",
    "## üèóÔ∏è Architecture Overview\n",
    "- **Model**: GIST Transformer (adapted from GRIT)\n",
    "- **Training**: Two-stage approach (8:1:1 split ‚Üí full dataset fine-tuning)\n",
    "- **Encoding**: RRWP positional encoding for molecular graphs\n",
    "- **Output**: Individual regression models for each property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check and basic imports\n",
    "import sys, torch, platform\n",
    "print(\"Python :\", sys.version)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA   :\", torch.version.cuda)\n",
    "print(\"Arch   :\", platform.machine())"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =====================================\n# üéØ GIST HYPERPARAMETER TUNING VARIABLES\n# =====================================\n# Modify these variables to tune model performance\n# These will override the values in polymer-GIST-RRWP.yaml\n\nprint(\"üéõÔ∏è Setting up GIST hyperparameter tuning variables...\")\n\n# ==== HIGH PRIORITY PARAMETERS (Major Impact on Performance) ====\n\n# Learning Rate - Controls training speed and convergence\n# Recommended: [1e-4, 5e-4, 1e-3, 2e-3]\nBASE_LR = 1e-3\n\n# Model Depth - Number of Transformer layers  \n# Recommended: [8, 10, 12, 14] (more layers = more capacity but slower)\nGT_LAYERS = 10\n\n# Hidden Dimension - Model width/capacity\n# Recommended: [64, 128, 192] (higher = more capacity but more memory)\nGT_DIM_HIDDEN = 64\n\n# Batch Size - Training batch size\n# Recommended: [16, 32, 64] (higher = more stable but more memory)\nBATCH_SIZE = 32\n\n# ==== MEDIUM PRIORITY PARAMETERS (Moderate Impact) ====\n\n# Dropout Rate - Regularization strength\n# Recommended: [0.0, 0.1, 0.2] (higher = more regularization)\nGT_DROPOUT = 0.0\n\n# Attention Heads - Multi-head attention\n# Recommended: [4, 6, 8, 12] (should divide dim_hidden evenly)\nGT_N_HEADS = 8\n\n# Weight Decay - L2 regularization\n# Recommended: [1e-6, 1e-5, 1e-4] (higher = more regularization)  \nWEIGHT_DECAY = 1e-5\n\n# Training Epochs - Total training steps\n# Recommended: [150, 200, 300] (more = longer training)\nMAX_EPOCH = 200\n\n# Attention Dropout - Regularization for attention mechanism\n# Recommended: [0.0, 0.1, 0.2, 0.3]\nATTN_DROPOUT = 0.2\n\n# ==== PARAMETER SOURCE CONFIRMATION ====\nprint(\"=\" * 80)\nprint(\"üîî PARAMETER SOURCE CONFIRMATION (GIST)\")\nprint(\"=\" * 80)\nprint(\"‚úÖ USING NOTEBOOK HYPERPARAMETER VARIABLES (NOT polymer-GIST-RRWP.yaml)\")\nprint(\"üìã The following parameters will OVERRIDE the YAML file:\")\n\nprint(\"\\nüìä Current GIST Hyperparameter Settings (FROM NOTEBOOK VARIABLES):\")\nprint(f\"   üéØ Learning Rate (BASE_LR): {BASE_LR} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Model Layers (GT_LAYERS): {GT_LAYERS} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Hidden Dimension (GT_DIM_HIDDEN): {GT_DIM_HIDDEN} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Batch Size (BATCH_SIZE): {BATCH_SIZE} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Dropout (GT_DROPOUT): {GT_DROPOUT} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Attention Heads (GT_N_HEADS): {GT_N_HEADS} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Weight Decay (WEIGHT_DECAY): {WEIGHT_DECAY} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Max Epochs (MAX_EPOCH): {MAX_EPOCH} ‚Üê FROM NOTEBOOK\")\nprint(f\"   üéØ Attention Dropout (ATTN_DROPOUT): {ATTN_DROPOUT} ‚Üê FROM NOTEBOOK\")\n\n# ==== VALIDATION CHECKS ====\nprint(\"\\nüîç Parameter Validation:\")\n# Check if attention heads divide hidden dimension evenly\nif GT_DIM_HIDDEN % GT_N_HEADS != 0:\n    print(f\"‚ö†Ô∏è  WARNING: GT_DIM_HIDDEN ({GT_DIM_HIDDEN}) should be divisible by GT_N_HEADS ({GT_N_HEADS})\")\n    print(f\"   Recommended GT_N_HEADS for dim_hidden={GT_DIM_HIDDEN}: {[i for i in [4,6,8,12,16] if GT_DIM_HIDDEN % i == 0]}\")\nelse:\n    print(f\"‚úÖ GT_DIM_HIDDEN ({GT_DIM_HIDDEN}) is divisible by GT_N_HEADS ({GT_N_HEADS})\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ GIST hyperparameter variables initialized successfully!\")\nprint(\"üéØ These values will be used instead of polymer-GIST-RRWP.yaml\")\nprint(\"üí° To tune performance, modify the variables above and re-run this cell\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle Environment Setup\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle paths for GIST\n",
    "TRAIN_CSV = Path('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\n",
    "TEST_CSV = Path('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')  \n",
    "SUPPLEMENT_DIR = Path('/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement')\n",
    "GIST_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/GIST')\n",
    "PIPELINE_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/full_pipeline.py')\n",
    "CONFIG_SOURCE = Path('/kaggle/input/gist/pytorch/default/1/neurips_challenge/configs')\n",
    "KAGGLE_WORKING = Path('/kaggle/working')\n",
    "\n",
    "print(\"üîç Kaggle Environment Setup (GIST)\")\n",
    "print(f\"üìñ Pipeline Source: {PIPELINE_SOURCE}\")\n",
    "print(f\"üìñ Config Source: {CONFIG_SOURCE}\")\n",
    "print(f\"üìñ GIST Source: {GIST_SOURCE}\")\n",
    "print(f\"‚úèÔ∏è  Working Directory: {KAGGLE_WORKING}\")\n",
    "\n",
    "# Install offline wheels\n",
    "try:\n",
    "    exec(open('/kaggle/input/grit-wheels-supplement/neurips-offline-wheels-truly-offline/install_offline.py').read())\n",
    "    exec(open('/kaggle/input/grit-wheels/install_offline.py').read())\n",
    "    print(\"‚úÖ Offline wheels installed\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Offline wheels installation failed (expected in local testing)\")\n",
    "\n",
    "# Create working directories\n",
    "working_dirs = ['graphs', 'results', 'cfg_runs', 'checkpoints', 'logs', 'GIST']\n",
    "for subdir in working_dirs:\n",
    "    (KAGGLE_WORKING / subdir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "# Add to Python path\n",
    "sys.path.insert(0, str(KAGGLE_WORKING))\n",
    "print(f\"‚úÖ Environment ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Copy and Setup GIST Architecture with Dynamic Configuration\nimport shutil\nimport yaml\n\nprint(\"üîß Setting up GIST architecture...\")\n\n# Copy GIST source code\ntry:\n    if GIST_SOURCE.exists():\n        writable_gist = KAGGLE_WORKING / \"GIST\"\n        if writable_gist.exists():\n            shutil.rmtree(writable_gist)\n        shutil.copytree(GIST_SOURCE, writable_gist)\n        print(f\"‚úÖ GIST copied to: {writable_gist}\")\n        \n        # Fix OGB smiles2graph import issue (same as GRIT)\n        print(\"üîß Patching OGB smiles2graph imports...\")\n        ogb_implementation = '''# ===== OGB SMILES2GRAPH IMPLEMENTATION =====\nimport numpy as np\nfrom rdkit import Chem\n\nallowable_features = {\n    'possible_atomic_num_list': list(range(1, 119)) + ['misc'],\n    'possible_chirality_list': ['CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW', 'CHI_OTHER', 'misc'],\n    'possible_degree_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n    'possible_formal_charge_list': [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n    'possible_numH_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 'misc'],\n    'possible_number_radical_e_list': [0, 1, 2, 3, 4, 'misc'],\n    'possible_hybridization_list': ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'],\n    'possible_is_aromatic_list': [False, True],\n    'possible_is_in_ring_list': [False, True],\n    'possible_bond_type_list': ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC', 'misc'],\n    'possible_bond_stereo_list': ['STEREONONE', 'STEREOZ', 'STEREOE', 'STEREOCIS', 'STEREOTRANS', 'STEREOANY'],\n    'possible_is_conjugated_list': [False, True]\n}\n\ndef safe_index(l, e):\n    try:\n        return l.index(e)\n    except:\n        return len(l) - 1\n\ndef atom_to_feature_vector(atom):\n    atom_feature = [\n        safe_index(allowable_features['possible_atomic_num_list'], atom.GetAtomicNum()),\n        safe_index(allowable_features['possible_chirality_list'], str(atom.GetChiralTag())),\n        safe_index(allowable_features['possible_degree_list'], atom.GetTotalDegree()),\n        safe_index(allowable_features['possible_formal_charge_list'], atom.GetFormalCharge()),\n        safe_index(allowable_features['possible_numH_list'], atom.GetTotalNumHs()),\n        safe_index(allowable_features['possible_number_radical_e_list'], atom.GetNumRadicalElectrons()),\n        safe_index(allowable_features['possible_hybridization_list'], str(atom.GetHybridization())),\n        allowable_features['possible_is_aromatic_list'].index(atom.GetIsAromatic()),\n        allowable_features['possible_is_in_ring_list'].index(atom.IsInRing()),\n    ]\n    return atom_feature\n\ndef bond_to_feature_vector(bond):\n    bond_feature = [\n        safe_index(allowable_features['possible_bond_type_list'], str(bond.GetBondType())),\n        allowable_features['possible_bond_stereo_list'].index(str(bond.GetStereo())),\n        allowable_features['possible_is_conjugated_list'].index(bond.GetIsConjugated()),\n    ]\n    return bond_feature\n\ndef smiles2graph(smiles_string):\n    mol = Chem.MolFromSmiles(smiles_string)\n    atom_features_list = []\n    for atom in mol.GetAtoms():\n        atom_features_list.append(atom_to_feature_vector(atom))\n    x = np.array(atom_features_list, dtype=np.int64)\n    \n    num_bond_features = 3\n    if len(mol.GetBonds()) > 0:\n        edges_list = []\n        edge_features_list = []\n        for bond in mol.GetBonds():\n            i = bond.GetBeginAtomIdx()\n            j = bond.GetEndAtomIdx()\n            edge_feature = bond_to_feature_vector(bond)\n            edges_list.append((i, j))\n            edge_features_list.append(edge_feature)\n            edges_list.append((j, i))\n            edge_features_list.append(edge_feature)\n        edge_index = np.array(edges_list, dtype=np.int64).T\n        edge_attr = np.array(edge_features_list, dtype=np.int64)\n    else:\n        edge_index = np.empty((2, 0), dtype=np.int64)\n        edge_attr = np.empty((0, num_bond_features), dtype=np.int64)\n    \n    graph = dict()\n    graph['edge_index'] = edge_index\n    graph['edge_feat'] = edge_attr\n    graph['node_feat'] = x\n    graph['num_nodes'] = len(x)\n    return graph\n# ===== END OGB IMPLEMENTATION ====='''\n        \n        # Patch files that use OGB\n        ogb_files = [\n            writable_gist / \"grit\" / \"loader\" / \"dataset\" / \"peptides_structural.py\",\n            writable_gist / \"grit\" / \"loader\" / \"dataset\" / \"peptides_functional.py\"\n        ]\n        \n        for ogb_file in ogb_files:\n            if ogb_file.exists():\n                with open(ogb_file, 'r') as f:\n                    content = f.read()\n                if \"from ogb.utils import smiles2graph\" in content:\n                    content = content.replace(\"from ogb.utils import smiles2graph\", ogb_implementation)\n                    with open(ogb_file, 'w') as f:\n                        f.write(content)\n                    print(f\"  ‚úÖ Patched: {ogb_file.name}\")\n        \n    else:\n        print(\"‚ö†Ô∏è  GIST source not found (expected in local testing)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  GIST setup failed: {e}\")\n\n# Create Dynamic Config with Notebook Hyperparameters\nprint(\"üéõÔ∏è Creating GIST config with notebook hyperparameters...\")\n\n# Read and copy the GIST configuration\ntry:\n    config_files = list(CONFIG_SOURCE.glob('*.yaml'))\n    if config_files:\n        gist_config = config_files[0]  # Use first available config\n        with open(gist_config, 'r') as f:\n            config = yaml.safe_load(f)\n        \n        print(f\"üìñ Read base GIST config from: {gist_config}\")\n        \n        # Override with notebook hyperparameters  \n        config['train']['batch_size'] = BATCH_SIZE\n        config['gt']['layers'] = GT_LAYERS\n        config['gt']['n_heads'] = GT_N_HEADS\n        config['gt']['dim_hidden'] = GT_DIM_HIDDEN\n        config['gt']['dropout'] = GT_DROPOUT\n        config['gt']['attn_dropout'] = ATTN_DROPOUT\n        config['optim']['base_lr'] = BASE_LR\n        config['optim']['weight_decay'] = WEIGHT_DECAY  \n        config['optim']['max_epoch'] = MAX_EPOCH\n        \n        # Adaptive settings\n        config['optim']['num_warmup_epochs'] = max(10, MAX_EPOCH // 4)\n        config['optim']['min_lr'] = BASE_LR / 100\n        config['gnn']['dim_inner'] = GT_DIM_HIDDEN\n        config['gnn']['dropout'] = GT_DROPOUT\n        \n        # Adapt for Kaggle paths\n        config['out_dir'] = str(KAGGLE_WORKING / 'results')\n        config['tensorboard_each_run'] = False  # Disable for Kaggle\n        \n        # Save adapted config\n        kaggle_config_path = KAGGLE_WORKING / 'polymer-GIST-RRWP.yaml'\n        with open(kaggle_config_path, 'w') as f:\n            yaml.safe_dump(config, f, sort_keys=False, default_flow_style=False)\n        \n        print(f\"‚úÖ Dynamic GIST config saved: {kaggle_config_path}\")\n        \n        print(f\"\\nüìä Using Notebook Hyperparameters (GIST):\")\n        print(f\"  üéØ Learning Rate: {BASE_LR}\")\n        print(f\"  üéØ GT Layers: {GT_LAYERS}\")\n        print(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")  \n        print(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\n        print(f\"  üéØ Batch Size: {BATCH_SIZE}\")\n        print(f\"  üéØ Dropout: {GT_DROPOUT}\")\n        print(f\"  üéØ Weight Decay: {WEIGHT_DECAY}\")\n        print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n        print(f\"  üìä TensorBoard: Disabled (Kaggle compatibility)\")\n        \n        print(f\"\\nüîî CONFIG CONFIRMED: Using GIST notebook variables instead of original YAML\")\n    else:\n        print(\"‚ö†Ô∏è  No GIST config files found\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Config setup failed: {e}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Execute Pipeline with GIST Architecture and Notebook Hyperparameters\nimport importlib.util\nimport torch\n\nprint(\"üöÄ Executing full_pipeline.py with GIST architecture...\")\n\n# Read and adapt pipeline for Kaggle paths\nwith open(PIPELINE_SOURCE, 'r') as f:\n    pipeline_code = f.read()\n\n# Apply comprehensive Kaggle path fixes\nkaggle_fixes = {\n    # Basic paths\n    'GIST_DIR = Path(__file__).resolve().parent / \"GIST\"': 'GIST_DIR = Path(\"/kaggle/working/GIST\")',\n    'ROOT        = Path(__file__).resolve().parent': 'ROOT = Path(\"/kaggle/working\")',\n    'DATA_ROOT   = ROOT / \"data\"': 'DATA_ROOT = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025\")',\n    'SUPP_DIR    = DATA_ROOT / \"train_supplement\"': 'SUPP_DIR = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement\")',\n    'GRAPH_DIR   = SUPP_DIR / \"graphs\"': 'GRAPH_DIR = Path(\"/kaggle/working/graphs\")',\n    'RESULTS_DIR = ROOT / \"results\"': 'RESULTS_DIR = Path(\"/kaggle/working/results\")',\n    \"sub_out.to_csv(ROOT/'submission.csv', index=False)\": 'sub_out.to_csv(\"/kaggle/working/submission.csv\", index=False)',\n    'dataset = PolymerDS_class(root=DATA_ROOT, target_idx=gym_cfg.dataset.target_idx)': 'dataset = PolymerDS_class(root=Path(\"/kaggle/working\"), target_idx=gym_cfg.dataset.target_idx)',\n    \n    # Fix the train_supplement/graphs path issue\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"train_graphs.pt\"': 'Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"test_graphs.pt\"': 'Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    \n    # Additional graph file references\n    'torch.save(graphs, GRAPH_DIR / \"train_graphs.pt\")': 'torch.save(graphs, Path(\"/kaggle/working/graphs/train_graphs.pt\"))',\n    'torch.save(t_graphs, GRAPH_DIR / \"test_graphs.pt\")': 'torch.save(t_graphs, Path(\"/kaggle/working/graphs/test_graphs.pt\"))',\n    'torch.load(GRAPH_DIR / \"train_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'torch.load(GRAPH_DIR / \"test_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    '(GRAPH_DIR / \"train_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/train_graphs.pt\").exists()',\n    '(GRAPH_DIR / \"test_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/test_graphs.pt\").exists()',\n    \n    # Dataset file references\n    'DATA_ROOT / \"train.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\")',\n    'DATA_ROOT / \"test.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\")',\n    'SUPP_DIR / \"dataset1.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\")',\n    'SUPP_DIR / \"dataset2.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset2.csv\")',\n    'SUPP_DIR / \"dataset3.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\")',\n    'SUPP_DIR / \"dataset4.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\")',\n    \n    # Other results paths\n    'report_path = save_dir / \"stage1_evaluation_report_gist.csv\"': 'report_path = Path(\"/kaggle/working/stage1_evaluation_report_gist.csv\")',\n    'CONFIG_SAVE = RESULTS_DIR / \"cfg_runs\"': 'CONFIG_SAVE = Path(\"/kaggle/working/cfg_runs\")',\n    \n    # Fix sample submission path\n    'DATA_ROOT/\\'sample_submission.csv\\'': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/sample_submission.csv\")',\n}\n\nfor old, new in kaggle_fixes.items():\n    pipeline_code = pipeline_code.replace(old, new)\n\n# Save adapted pipeline\nkaggle_pipeline = KAGGLE_WORKING / 'full_pipeline_gist_kaggle.py' \nwith open(kaggle_pipeline, 'w') as f:\n    f.write(pipeline_code)\n\nprint(f\"‚úÖ GIST Pipeline adapted for Kaggle: {kaggle_pipeline}\")\n\n# Execute pipeline\ntry:\n    spec = importlib.util.spec_from_file_location(\"kaggle_gist_pipeline\", kaggle_pipeline)\n    pipeline_module = importlib.util.module_from_spec(spec)\n    \n    # Set command line args\n    original_argv = sys.argv.copy()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    sys.argv = ['full_pipeline_gist_kaggle.py', '--cfg', str(kaggle_config_path), '--device', device]\n    \n    print(f\"‚öôÔ∏è  Config: {kaggle_config_path}\")\n    print(f\"üñ•Ô∏è  Device: {device}\")\n    print(f\"üèóÔ∏è  Architecture: GIST Transformer\")\n    print(f\"üìä Training Strategy: Two-stage (8:1:1 ‚Üí Full dataset)\")\n    \n    print(f\"\\nüéõÔ∏è TRAINING WITH NOTEBOOK HYPERPARAMETERS (GIST):\")\n    print(f\"  üéØ Learning Rate: {BASE_LR}\")\n    print(f\"  üéØ GT Layers: {GT_LAYERS}\")\n    print(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")\n    print(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\n    print(f\"  üéØ Batch Size: {BATCH_SIZE}\")\n    print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n    \n    # Execute\n    spec.loader.exec_module(pipeline_module)\n    if hasattr(pipeline_module, 'main'):\n        pipeline_module.main()\n        print(f\"\\nüéâ GIST training completed!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n    print(\"üìã This may be expected in local testing - will work on Kaggle\")\n    \nfinally:\n    sys.argv = original_argv"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Analysis\n",
    "print(\"=\"*60)\n",
    "print(\"üìä GIST TRAINING RESULTS ANALYSIS\")  \n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for results files using KAGGLE_WORKING paths\n",
    "submission_file = KAGGLE_WORKING / \"submission.csv\"\n",
    "eval_report = KAGGLE_WORKING / \"stage1_evaluation_report_gist.csv\"\n",
    "results_dir = KAGGLE_WORKING / \"results\"\n",
    "\n",
    "print(f\"üìÅ Results directory: {results_dir}\")\n",
    "print(f\"üìÑ Submission file: {submission_file}\")\n",
    "print(f\"üìã Evaluation report: {eval_report}\")\n",
    "\n",
    "# Analyze submission file\n",
    "if submission_file.exists():\n",
    "    print(f\"\\n‚úÖ Submission file found: {submission_file}\")\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "        submission = pd.read_csv(submission_file)\n",
    "        print(f\"üìä Submission shape: {submission.shape}\")\n",
    "        \n",
    "        # Show column info\n",
    "        expected_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "        actual_cols = list(submission.columns)\n",
    "        print(f\"üìã Columns: {actual_cols}\")\n",
    "        \n",
    "        missing_cols = set(expected_cols) - set(actual_cols)\n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All required columns present\")\n",
    "        \n",
    "        # Show prediction statistics\n",
    "        print(f\"\\nüìà Prediction Statistics:\")\n",
    "        for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n",
    "            if target in submission.columns:\n",
    "                values = submission[target]\n",
    "                print(f\"  {target:8s}: mean={values.mean():7.3f}, std={values.std():7.3f}, range=[{values.min():6.3f}, {values.max():6.3f}]\")\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(f\"\\nüìÑ Sample Predictions:\")\n",
    "        print(submission.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading submission: {e}\")\nelse:\n",
    "    print(f\"‚ùå No submission file found\")\n",
    "\n",
    "# Analyze evaluation report\n",
    "if eval_report.exists():\n",
    "    print(f\"\\n‚úÖ Evaluation report found: {eval_report}\")\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        eval_df = pd.read_csv(eval_report)\n",
    "        print(\"\\nüèÜ GIST Model Performance Summary:\")\n",
    "        \n",
    "        # Show available columns\n",
    "        display_cols = ['Target', 'Performance_Grade', 'Performance_Level', 'Relative_Error', 'MAE', 'Test_MAE']\n",
    "        available_cols = [col for col in display_cols if col in eval_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(eval_df[available_cols].to_string(index=False))\n",
    "        else:\n",
    "            print(eval_df.to_string(index=False))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading evaluation report: {e}\")\nelse:\n",
    "    print(f\"‚ùå No evaluation report found\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üèóÔ∏è GIST ARCHITECTURE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ GIST Transformer features:\")\n",
    "print(\"  üèóÔ∏è  Architecture: Graph Transformer with RRWP encoding\")\n",
    "print(\"  üìä Training: Two-stage approach (8:1:1 ‚Üí Full dataset)\")\n",
    "print(\"  üéØ Targets: 5 independent models (Tg, FFV, Tc, Density, Rg)\")\n",
    "print(\"  ‚ö° Optimization: Stage 2 models used for final predictions\")\n",
    "print(f\"\\nüìÅ Output files:\")\n",
    "print(f\"  üìÑ Submission: {submission_file}\")\n",
    "print(f\"  üìã Evaluation: {eval_report}\")\n",
    "print(f\"  üìÅ Results: {results_dir}\")\n",
    "print(f\"\\nüéâ GIST training pipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results verification\n",
    "print(\"=\" * 60)\n",
    "print(\"üìã GIST RESULTS VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check submission file\n",
    "submission_path = KAGGLE_WORKING / 'submission.csv'\n",
    "if submission_path.exists():\n",
    "    print(f\"‚úÖ Submission file created: {submission_path}\")\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "        submission = pd.read_csv(submission_path)\n",
    "        print(f\"üìä Submission shape: {submission.shape}\")\n",
    "        \n",
    "        # Check required columns\n",
    "        expected_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "        actual_cols = list(submission.columns)\n",
    "        \n",
    "        print(f\"üìã Columns found: {actual_cols}\")\n",
    "        missing_cols = set(expected_cols) - set(actual_cols)\n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All required columns present\")\n",
    "        \n",
    "        # Show prediction statistics\n",
    "        print(\"\\nüìà Prediction Statistics:\")\n",
    "        for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n",
    "            if target in submission.columns:\n",
    "                values = submission[target]\n",
    "                print(f\"  {target:8s}: mean={values.mean():7.3f}, std={values.std():7.3f}, range=[{values.min():6.3f}, {values.max():6.3f}]\")\n",
    "        \n",
    "        # Show preview\n",
    "        print(f\"\\nüìÑ Submission Preview:\")\n",
    "        print(submission.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing submission: {e}\")\n",
    "        \nelse:\n",
    "    print(f\"‚ùå No submission file found at: {submission_path}\")\n",
    "\n",
    "# Check evaluation report\n",
    "eval_report_path = KAGGLE_WORKING / 'stage1_evaluation_report_gist.csv'\n",
    "if eval_report_path.exists():\n",
    "    print(f\"\\n‚úÖ Training evaluation report: {eval_report_path}\")\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        eval_df = pd.read_csv(eval_report_path)\n",
    "        print(\"üèÜ GIST Model Performance Summary:\")\n",
    "        display_cols = ['Target', 'Performance_Grade', 'Performance_Level', 'Relative_Error']\n",
    "        available_cols = [col for col in display_cols if col in eval_df.columns]\n",
    "        if available_cols:\n",
    "            print(eval_df[available_cols].to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading evaluation report: {e}\")\n",
    "\n",
    "# Final status\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéØ FINAL STATUS (GIST)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "status_checks = [\n",
    "    (\"Competition data found\", TRAIN_CSV.exists() and TEST_CSV.exists()),\n",
    "    (\"GIST copied successfully\", (KAGGLE_WORKING / \"GIST\").exists()),\n",
    "    (\"Configuration created\", (KAGGLE_WORKING / 'polymer-GIST-RRWP.yaml').exists()),\n",
    "    (\"Pipeline adapted\", (KAGGLE_WORKING / 'full_pipeline_gist_kaggle.py').exists()),\n",
    "    (\"Submission generated\", submission_path.exists()),\n",
    "]\n",
    "\n",
    "all_good = True\n",
    "for check_name, status in status_checks:\n",
    "    icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"{icon} {check_name}\")\n",
    "    if not status:\n",
    "        all_good = False\n",
    "\n",
    "if all_good and submission_path.exists():\n",
    "    print(f\"\\nüéâ SUCCESS! Kaggle submission ready (GIST Architecture)\")\n",
    "    print(f\"üèóÔ∏è  Architecture: GIST Transformer\")\n",
    "    print(f\"üìÑ Submit file: /kaggle/working/submission.csv\")\n",
    "    print(f\"üì¶ File size: {submission_path.stat().st_size / 1024:.1f} KB\")\nelse:\n",
    "    print(f\"\\n‚ö†Ô∏è  Issues detected - check error messages above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ GIST Architecture Summary\n",
    "\n",
    "This notebook successfully implements the **GIST (Graph Transformer)** architecture for polymer property prediction:\n",
    "\n",
    "### üèóÔ∏è Key Features:\n",
    "- **Architecture**: GIST Transformer with RRWP positional encoding\n",
    "- **Training Strategy**: Two-stage approach (8:1:1 split ‚Üí full dataset fine-tuning)\n",
    "- **Multi-target**: 5 independent regression models for each property\n",
    "- **Optimization**: Stage 2 models provide final predictions\n",
    "\n",
    "### üìä Properties Predicted:\n",
    "1. **Tg**: Glass Transition Temperature\n",
    "2. **FFV**: Fractional Free Volume\n",
    "3. **Tc**: Thermal Conductivity  \n",
    "4. **Density**: Material Density\n",
    "5. **Rg**: Radius of Gyration\n",
    "\n",
    "### üéâ Results:\n",
    "- **Submission file**: `/kaggle/working/submission.csv`\n",
    "- **Evaluation report**: `/kaggle/working/stage1_evaluation_report_gist.csv`\n",
    "- **Training logs**: `/kaggle/working/results/`\n",
    "\n",
    "The GIST architecture provides state-of-the-art graph transformer capabilities optimized for molecular property prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# üéõÔ∏è GIST Hyperparameter Tuning Guide\n\n## üìã Quick Reference\n\nTo adjust model performance, modify the variables in **Cell 2** (GIST Hyperparameter Variables) and re-run the notebook.\n\n### üéØ High Priority Parameters (Major Impact)\n\n| Parameter | Current | Recommended Values | Impact |\n|-----------|---------|-------------------|---------| \n| `BASE_LR` | 1e-3 | [1e-4, 5e-4, 1e-3, 2e-3] | Learning speed & convergence |\n| `GT_LAYERS` | 10 | [8, 10, 12, 14] | Model capacity & training time |\n| `GT_DIM_HIDDEN` | 64 | [64, 128, 192] | Model width & memory usage |\n| `BATCH_SIZE` | 32 | [16, 32, 64] | Training stability & memory |\n\n### üéöÔ∏è Medium Priority Parameters\n\n| Parameter | Current | Recommended Values | Impact |\n|-----------|---------|-------------------|---------| \n| `GT_DROPOUT` | 0.0 | [0.0, 0.1, 0.2] | Regularization strength |\n| `GT_N_HEADS` | 8 | [4, 6, 8, 12] | Attention mechanism |\n| `WEIGHT_DECAY` | 1e-5 | [1e-6, 1e-5, 1e-4] | L2 regularization |\n| `MAX_EPOCH` | 200 | [150, 200, 300] | Training duration |\n\n## üöÄ GIST-Specific Tuning Strategy\n\n### For Better Performance:\n- **Increase**: `GT_LAYERS` (10‚Üí12), `GT_DIM_HIDDEN` (64‚Üí128)\n- **Adjust**: `BASE_LR` (try 5e-4 or 2e-3)  \n- **Add regularization**: `GT_DROPOUT` (0.0‚Üí0.1)\n\n### For Faster Training:\n- **Decrease**: `GT_LAYERS` (10‚Üí8), `MAX_EPOCH` (200‚Üí150)\n- **Increase**: `BATCH_SIZE` (32‚Üí64)\n\n### For Memory Issues:\n- **Decrease**: `BATCH_SIZE` (32‚Üí16), `GT_DIM_HIDDEN` (64‚Üí32)\n- **Reduce**: `GT_LAYERS` (10‚Üí8)\n\n## üìä Model Performance Grades\n\nThe notebook will show performance grades for each target:\n- **A+/A**: Excellent (< 8% relative error)\n- **B+/B**: Good (< 18% relative error)  \n- **C**: Acceptable (< 25% relative error)\n- **D**: Poor (> 25% relative error)\n\n## üîÑ How to Tune\n\n1. **Modify variables** in Cell 2 (GIST Hyperparameter Variables)\n2. **Re-run** the entire notebook from Cell 2 onwards\n3. **Check results** in the final cell for performance grades\n4. **Iterate** based on performance and time constraints\n\n## üí° GIST Pro Tips\n\n- Start with learning rate: try `BASE_LR = 5e-4` or `2e-3`\n- For overfitting: increase `GT_DROPOUT` to 0.1-0.2\n- For underfitting: increase `GT_LAYERS` or `GT_DIM_HIDDEN`\n- Ensure `GT_DIM_HIDDEN` is divisible by `GT_N_HEADS`\n- GIST benefits from larger hidden dimensions compared to standard GNNs\n\n## üèóÔ∏è GIST vs GRIT Differences\n\n- **GIST**: Improved graph transformer with better attention mechanisms\n- **Training**: Same two-stage approach works well for both\n- **Memory**: GIST may use slightly more memory per layer\n- **Performance**: GIST often achieves better results on graph regression tasks",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}