{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "# Environment check and basic imports\nimport sys, torch, platform\nprint(\"Python :\", sys.version)\nprint(\"PyTorch:\", torch.__version__)\nprint(\"CUDA   :\", torch.version.cuda)\nprint(\"Arch   :\", platform.machine())\n\n# Install offline wheels for Kaggle compatibility\nprint(\"Kaggle Environment Setup...\")\nexec(open('/kaggle/input/grit-wheels-supplement/neurips-offline-wheels-truly-offline/install_offline.py').read())\nexec(open('/kaggle/input/grit-wheels/install_offline.py').read())\n\n# Import essential libraries\nfrom pathlib import Path\nimport yaml\n\n# Define all necessary paths for Kaggle environment\nKAGGLE_WORKING = Path(\"/kaggle/working\")\nKAGGLE_INPUT = Path(\"/kaggle/input\")\n\n# Pipeline and configuration paths\nPIPELINE_SOURCE = KAGGLE_INPUT / \"grit/pytorch/default/1/neurips_challenge/full_pipeline.py\"\nCONFIG_SOURCE = KAGGLE_INPUT / \"grit/pytorch/default/1/neurips_challenge\"\nGRIT_SOURCE = KAGGLE_INPUT / \"grit/pytorch/default/1/neurips_challenge/GRIT\"\n\n# Data paths\nTRAIN_CSV = KAGGLE_INPUT / \"neurips-open-polymer-prediction-2025/train.csv\"\nTEST_CSV = KAGGLE_INPUT / \"neurips-open-polymer-prediction-2025/test.csv\"\n\nprint(\"‚úÖ Environment setup completed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphAug configuration variables\n",
    "GRAPHAUG_SOURCE = '/kaggle/input/graphaug/pytorch/default/1/GraphAug/src'\n",
    "\n",
    "# Data augmentation settings\n",
    "USE_SUBMIX = True\n",
    "SUBMIX_AUG_SIZE = 0.4\n",
    "SUBMIX_ROOT_MODE = 'random'  # 'random', 'positional', 'important'\n",
    "\n",
    "USE_NODESAM = True\n",
    "NODESAM_ADJUSTMENT = True\n",
    "\n",
    "USE_DROPEDGE = True\n",
    "\n",
    "USE_DROPNODE = True"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =====================================\n# üéõÔ∏è GRIT HYPERPARAMETER VARIABLES  \n# =====================================\n# Configure GRIT Transformer model parameters\n# These variables override the polymer-GRIT-RRWP.yaml configuration\n\nprint(\"üéõÔ∏è Setting up GRIT hyperparameter variables...\")\n\n# ==== HIGH PRIORITY PARAMETERS (Major Impact) ====\n# Learning rate - controls training speed and convergence\n# Recommended: [1e-4, 5e-4, 1e-3, 2e-3] (higher = faster but less stable)\nBASE_LR = 1e-3\n\n# Number of Graph Transformer layers - model depth\n# Recommended: [8, 10, 12, 14] (higher = more capacity, longer training)\nGT_LAYERS = 10\n\n# Hidden dimension size - model width\n# Recommended: [64, 128, 192] (higher = more capacity, more memory)\nGT_DIM_HIDDEN = 64\n\n# Batch size - number of molecules per training step\n# Recommended: [16, 32, 64] (higher = faster, more memory)\nBATCH_SIZE = 32\n\n# ==== MEDIUM PRIORITY PARAMETERS ====\n# Dropout rate - regularization strength\n# Recommended: [0.0, 0.1, 0.2] (higher = more regularization)\nGT_DROPOUT = 0.0\n\n# Number of attention heads (must divide GT_DIM_HIDDEN evenly)\n# Recommended: [4, 6, 8, 12] \nGT_N_HEADS = 8\n\n# Attention dropout - specific regularization for attention\n# Recommended: [0.0, 0.1, 0.2]\nATTN_DROPOUT = 0.0\n\n# Weight decay - L2 regularization\n# Recommended: [1e-6, 1e-5, 1e-4] (higher = more regularization)\nWEIGHT_DECAY = 1e-5\n\n# Maximum training epochs\n# Recommended: [150, 200, 300] (higher = longer training)\nMAX_EPOCH = 200\n\n# ==== HYPERPARAMETER CONFIRMATION ====\nprint(\"=\" * 80)\nprint(\"üéõÔ∏è GRIT HYPERPARAMETERS CONFIGURED\")\nprint(\"=\" * 80)\nprint(\"üìã These parameters will override polymer-GRIT-RRWP.yaml settings:\")\n\nprint(f\"\\nüî• High Priority Parameters:\")\nprint(f\"   üéØ Learning Rate: {BASE_LR}\")\nprint(f\"   üèóÔ∏è  GT Layers: {GT_LAYERS}\")\nprint(f\"   üìè Hidden Dimension: {GT_DIM_HIDDEN}\")\nprint(f\"   üì¶ Batch Size: {BATCH_SIZE}\")\n\nprint(f\"\\n‚öôÔ∏è  Medium Priority Parameters:\")\nprint(f\"   üõ°Ô∏è  Dropout: {GT_DROPOUT}\")\nprint(f\"   üëÅÔ∏è  Attention Heads: {GT_N_HEADS}\")\nprint(f\"   üõ°Ô∏è  Attention Dropout: {ATTN_DROPOUT}\")\nprint(f\"   ‚öñÔ∏è  Weight Decay: {WEIGHT_DECAY}\")\nprint(f\"   üïê Max Epochs: {MAX_EPOCH}\")\n\nprint(f\"\\n‚úÖ Validation checks:\")\nif GT_DIM_HIDDEN % GT_N_HEADS == 0:\n    print(f\"   ‚úÖ Hidden dimension ({GT_DIM_HIDDEN}) is divisible by attention heads ({GT_N_HEADS})\")\nelse:\n    print(f\"   ‚ùå WARNING: Hidden dimension ({GT_DIM_HIDDEN}) not divisible by attention heads ({GT_N_HEADS})\")\n\nprint(f\"\\nüéØ Expected Impact:\")\nprint(f\"   ‚Ä¢ Learning Rate {BASE_LR}: {'Conservative' if BASE_LR <= 1e-3 else 'Aggressive'}\")\nprint(f\"   ‚Ä¢ Model Size ({GT_LAYERS} layers, {GT_DIM_HIDDEN}D): {'Compact' if GT_LAYERS <= 10 and GT_DIM_HIDDEN <= 64 else 'Large'}\")\nprint(f\"   ‚Ä¢ Regularization: {'Light' if GT_DROPOUT <= 0.1 else 'Heavy'}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Hyperparameters initialized!\")\nprint(\"üí° To modify parameters, change variables above and re-run\")\nprint(\"üîÑ Parameters will be applied to training configuration\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# =====================================\n",
    "# üß¨ GRAPHAUG DATA AUGMENTATION SETTINGS  \n",
    "# =====================================\n",
    "# Configure graph data augmentation for improved model performance\n",
    "# GraphAug methods help models generalize better on molecular graphs\n",
    "\n",
    "print(\"üß¨ Setting up GraphAug data augmentation variables...\")\n",
    "\n",
    "# ==== GRAPHAUG ENABLE/DISABLE ====\n",
    "GRAPHAUG_ENABLE = True  # Set to False to disable all augmentation\n",
    "\n",
    "# ==== AUGMENTATION METHOD ====\n",
    "# Available methods: 'SubMix', 'NodeSam', 'DropEdge', 'DropNode', 'ChangeAttr'\n",
    "# Recommended for molecular graphs: 'SubMix' (best chemistry preservation)\n",
    "GRAPHAUG_METHOD = 'SubMix'\n",
    "\n",
    "# ==== AUGMENTATION INTENSITY ====\n",
    "# Probability of applying augmentation to each batch\n",
    "# Recommended: [0.3, 0.5, 0.7] (higher = more augmentation)\n",
    "GRAPHAUG_PROB = 0.5\n",
    "\n",
    "# Augmentation strength/ratio\n",
    "# Recommended: [0.1, 0.3, 0.5] (higher = stronger augmentation)\n",
    "GRAPHAUG_RATIO = 0.3\n",
    "\n",
    "# ==== SUBMIX SPECIFIC PARAMETERS ====\n",
    "# Root node selection method for SubMix\n",
    "# Options: 'random', 'degree', 'pagerank'\n",
    "SUBMIX_ROOT_SELECTION = 'degree'\n",
    "\n",
    "# Whether to mix labels for SubMix (creates soft targets)\n",
    "# Recommended: True for better interpolation\n",
    "SUBMIX_LABEL_MIX = True\n",
    "\n",
    "# ==== NODESAM SPECIFIC PARAMETERS ====\n",
    "# Split mode for NodeSam augmentation  \n",
    "# Options: 'random', 'triangle_aware'\n",
    "NODESAM_SPLIT_MODE = 'triangle_aware'\n",
    "\n",
    "# Merge ratio for NodeSam\n",
    "# Recommended: [0.1, 0.2, 0.3]\n",
    "NODESAM_MERGE_RATIO = 0.2\n",
    "\n",
    "# ==== GRAPHAUG CONFIRMATION ====\n",
    "if GRAPHAUG_ENABLE:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üß¨ GRAPHAUG DATA AUGMENTATION ENABLED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìã GraphAug will enhance training with molecular-aware data augmentation:\")\n",
    "    \n",
    "    print(f\"\\nüî¨ GraphAug Configuration:\")\n",
    "    print(f\"   üß™ Method: {GRAPHAUG_METHOD}\")\n",
    "    print(f\"   üìä Probability: {GRAPHAUG_PROB} (apply to {GRAPHAUG_PROB*100:.0f}% of batches)\")\n",
    "    print(f\"   ‚ö° Intensity: {GRAPHAUG_RATIO}\")\n",
    "    \n",
    "    if GRAPHAUG_METHOD == 'SubMix':\n",
    "        print(f\"   üîó SubMix Root Selection: {SUBMIX_ROOT_SELECTION}\")\n",
    "        print(f\"   üéØ Label Mixing: {'Enabled' if SUBMIX_LABEL_MIX else 'Disabled'}\")\n",
    "    elif GRAPHAUG_METHOD == 'NodeSam':\n",
    "        print(f\"   ‚úÇÔ∏è  Split Mode: {NODESAM_SPLIT_MODE}\")\n",
    "        print(f\"   üîÄ Merge Ratio: {NODESAM_MERGE_RATIO}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Expected Benefits:\")\n",
    "    print(f\"   ‚úÖ Better generalization on diverse polymer structures\")\n",
    "    print(f\"   ‚úÖ Improved robustness to molecular variations\")\n",
    "    print(f\"   ‚úÖ Enhanced training data diversity\")\n",
    "    print(f\"   ‚úÖ Reduced overfitting on limited training data\")\n",
    "    \n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üö´ GRAPHAUG DATA AUGMENTATION DISABLED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìã Training will use standard GRIT without data augmentation\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ GraphAug configuration initialized!\")\n",
    "print(\"üí° To modify augmentation, change variables above and re-run\")\n",
    "print(\"üîÑ GraphAug will be integrated into the training pipeline\")\n",
    "print(\"=\" * 80)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T00:44:15.181605Z",
     "iopub.status.busy": "2025-08-07T00:44:15.181268Z",
     "iopub.status.idle": "2025-08-07T00:45:23.359325Z",
     "shell.execute_reply": "2025-08-07T00:45:23.357989Z",
     "shell.execute_reply.started": "2025-08-07T00:44:15.181582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Add GraphAug to path\n",
    "import sys\n",
    "if GRAPHAUG_SOURCE not in sys.path:\n",
    "    sys.path.append('/kaggle/input/graphaug/pytorch/default/1/GraphAug/src')\n",
    "\n",
    "# Import GraphAug modules\n",
    "try:\n",
    "    from augment.baselines.simple import DropEdge, DropNode\n",
    "    from augment.submix import SubMix\n",
    "    from augment.nodesam import NodeSam\n",
    "    print(\"‚úì GraphAug modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚úó Error importing GraphAug modules: {e}\")\n",
    "    print(\"GraphAug features will be disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-07T00:45:54.981520Z",
     "iopub.status.busy": "2025-08-07T00:45:54.981176Z",
     "iopub.status.idle": "2025-08-07T00:45:55.011240Z",
     "shell.execute_reply": "2025-08-07T00:45:55.009683Z",
     "shell.execute_reply.started": "2025-08-07T00:45:54.981496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": "# Create Dynamic Config with Notebook Hyperparameters and GraphAug\nimport yaml\n\nprint(\"üéõÔ∏è Creating config with notebook hyperparameters and GraphAug settings...\")\n\n# Read original config from Kaggle input (correct path with configs directory)\noriginal_config_path = CONFIG_SOURCE / 'configs/polymer-GRIT-RRWP.yaml'\nwith open(original_config_path, 'r') as f:\n    config = yaml.safe_load(f)\n\nprint(f\"üìñ Read base config from: {original_config_path}\")\n\n# Override with notebook hyperparameters  \nconfig['train']['batch_size'] = BATCH_SIZE\nconfig['gt']['layers'] = GT_LAYERS\nconfig['gt']['n_heads'] = GT_N_HEADS\nconfig['gt']['dim_hidden'] = GT_DIM_HIDDEN\nconfig['gt']['dropout'] = GT_DROPOUT\nconfig['gt']['attn_dropout'] = ATTN_DROPOUT\nconfig['optim']['base_lr'] = BASE_LR\nconfig['optim']['weight_decay'] = WEIGHT_DECAY  \nconfig['optim']['max_epoch'] = MAX_EPOCH\n\n# Adaptive settings\nconfig['optim']['num_warmup_epochs'] = max(10, MAX_EPOCH // 4)\nconfig['optim']['min_lr'] = BASE_LR / 100\nconfig['gnn']['dim_inner'] = GT_DIM_HIDDEN\nconfig['gnn']['dropout'] = GT_DROPOUT\n\n# Add GraphAug configuration\nconfig['graphaug'] = {\n    'enable': GRAPHAUG_ENABLE,\n    'method': GRAPHAUG_METHOD,\n    'prob': GRAPHAUG_PROB,\n    'aug_ratio': GRAPHAUG_RATIO,\n    \n    # SubMix specific settings\n    'submix': {\n        'root_selection': SUBMIX_ROOT_SELECTION,\n        'label_mix': SUBMIX_LABEL_MIX\n    },\n    \n    # NodeSam specific settings  \n    'nodesam': {\n        'split_mode': NODESAM_SPLIT_MODE,\n        'merge_ratio': NODESAM_MERGE_RATIO\n    }\n}\n\n# Disable tensorboard for Kaggle compatibility\nconfig['tensorboard_each_run'] = False\n\n# Save to working directory\ndynamic_config_path = KAGGLE_WORKING / 'polymer-GRIT-RRWP.yaml'\nwith open(dynamic_config_path, 'w') as f:\n    yaml.safe_dump(config, f, sort_keys=False, default_flow_style=False)\n\nprint(f\"‚úÖ Dynamic config saved: {dynamic_config_path}\")\n\nprint(f\"\\nüìä Using Notebook Hyperparameters:\")\nprint(f\"  üéØ Learning Rate: {BASE_LR}\")\nprint(f\"  üéØ GT Layers: {GT_LAYERS}\")\nprint(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")  \nprint(f\"  üéØ Attention Heads: {GT_N_HEADS}\")\nprint(f\"  üéØ Batch Size: {BATCH_SIZE}\")\nprint(f\"  üéØ Dropout: {GT_DROPOUT}\")\nprint(f\"  üéØ Weight Decay: {WEIGHT_DECAY}\")\nprint(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n\nprint(f\"\\nüß¨ GraphAug Data Augmentation:\")\nif GRAPHAUG_ENABLE:\n    print(f\"  üß™ Status: Enabled\")\n    print(f\"  üî¨ Method: {GRAPHAUG_METHOD}\")\n    print(f\"  üìä Probability: {GRAPHAUG_PROB}\")\n    print(f\"  ‚ö° Ratio: {GRAPHAUG_RATIO}\")\nelse:\n    print(f\"  üö´ Status: Disabled\")\n\nprint(f\"  üìä TensorBoard: Disabled (Kaggle compatibility)\")\n\nprint(f\"\\nüîî CONFIG CONFIRMED: Using notebook variables and GraphAug settings\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-07T00:46:10.143250Z",
     "iopub.status.busy": "2025-08-07T00:46:10.142809Z",
     "iopub.status.idle": "2025-08-07T00:46:13.524469Z",
     "shell.execute_reply": "2025-08-07T00:46:13.523099Z",
     "shell.execute_reply.started": "2025-08-07T00:46:10.143219Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": "# Execute Pipeline with GraphAug Data Augmentation Integration\nimport importlib.util\nimport torch\n\nprint(\"üöÄ Executing full_pipeline.py with GraphAug integration...\")\n\n# Read and adapt pipeline for Kaggle paths\nwith open(PIPELINE_SOURCE, 'r') as f:\n    pipeline_code = f.read()\n\n# Apply comprehensive Kaggle path fixes\nkaggle_fixes = {\n    # Basic paths\n    'GRIT_DIR = Path(__file__).resolve().parent / \"GRIT\"': 'GRIT_DIR = Path(\"/kaggle/working/GRIT\")',\n    'ROOT        = Path(__file__).resolve().parent': 'ROOT = Path(\"/kaggle/working\")',\n    'DATA_ROOT   = ROOT / \"data\"': 'DATA_ROOT = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025\")',\n    'SUPP_DIR    = DATA_ROOT / \"train_supplement\"': 'SUPP_DIR = Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement\")',\n    'GRAPH_DIR   = SUPP_DIR / \"graphs\"': 'GRAPH_DIR = Path(\"/kaggle/working/graphs\")',\n    'RESULTS_DIR = ROOT / \"results\"': 'RESULTS_DIR = Path(\"/kaggle/working/results\")',\n    \"sub_out.to_csv(ROOT/'submission.csv', index=False)\": 'sub_out.to_csv(\"/kaggle/working/submission.csv\", index=False)',\n    'dataset = PolymerDS_class(root=DATA_ROOT, target_idx=gym_cfg.dataset.target_idx)': 'dataset = PolymerDS_class(root=Path(\"/kaggle/working\"), target_idx=gym_cfg.dataset.target_idx)',\n    \n    # Fix the train_supplement/graphs path issue\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"train_graphs.pt\"': 'Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'Path(root) / \"train_supplement\" / \"graphs\" / \"test_graphs.pt\"': 'Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    \n    # Additional graph file references\n    'torch.save(graphs, GRAPH_DIR / \"train_graphs.pt\")': 'torch.save(graphs, Path(\"/kaggle/working/graphs/train_graphs.pt\"))',\n    'torch.save(t_graphs, GRAPH_DIR / \"test_graphs.pt\")': 'torch.save(t_graphs, Path(\"/kaggle/working/graphs/test_graphs.pt\"))',\n    'torch.load(GRAPH_DIR / \"train_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/train_graphs.pt\")',\n    'torch.load(GRAPH_DIR / \"test_graphs.pt\"': 'torch.load(Path(\"/kaggle/working/graphs/test_graphs.pt\")',\n    '(GRAPH_DIR / \"train_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/train_graphs.pt\").exists()',\n    '(GRAPH_DIR / \"test_graphs.pt\").exists()': 'Path(\"/kaggle/working/graphs/test_graphs.pt\").exists()',\n    \n    # Dataset file references\n    'DATA_ROOT / \"train.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train.csv\")',\n    'DATA_ROOT / \"test.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/test.csv\")',\n    'SUPP_DIR / \"dataset1.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset1.csv\")',\n    'SUPP_DIR / \"dataset2.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset2.csv\")',\n    'SUPP_DIR / \"dataset3.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset3.csv\")',\n    'SUPP_DIR / \"dataset4.csv\"': 'Path(\"/kaggle/input/neurips-open-polymer-prediction-2025/train_supplement/dataset4.csv\")',\n    \n    # Other results paths\n    'report_path = save_dir / \"stage1_evaluation_report.csv\"': 'report_path = Path(\"/kaggle/working/stage1_evaluation_report.csv\")',\n    'CONFIG_SAVE = RESULTS_DIR / \"cfg_runs\"': 'CONFIG_SAVE = Path(\"/kaggle/working/cfg_runs\")',\n}\n\nfor old, new in kaggle_fixes.items():\n    pipeline_code = pipeline_code.replace(old, new)\n\n# ===== GRAPHAUG INTEGRATION =====\nif GRAPHAUG_ENABLE:\n    print(\"üß¨ Integrating GraphAug data augmentation...\")\n    \n    # Add GraphAug variables and imports at the beginning of the pipeline\n    graphaug_setup = f\"\"\"\n# ===== GRAPHAUG CONFIGURATION =====\n# GraphAug variables from notebook\nGRAPHAUG_ENABLE = {GRAPHAUG_ENABLE}\nGRAPHAUG_METHOD = '{GRAPHAUG_METHOD}'\nGRAPHAUG_PROB = {GRAPHAUG_PROB}\nGRAPHAUG_RATIO = {GRAPHAUG_RATIO}\nSUBMIX_ROOT_SELECTION = '{SUBMIX_ROOT_SELECTION}'\nSUBMIX_LABEL_MIX = {SUBMIX_LABEL_MIX}\nNODESAM_SPLIT_MODE = '{NODESAM_SPLIT_MODE}'\nNODESAM_MERGE_RATIO = {NODESAM_MERGE_RATIO}\n\n# ===== GRAPHAUG IMPORTS AND SETUP =====\nimport random\nimport numpy as np\nfrom torch_geometric.data import Batch\n\n# GraphAug augmentation methods\nclass GraphAugmentor:\n    def __init__(self, method='SubMix', aug_ratio=0.3, **kwargs):\n        self.method = method\n        self.aug_ratio = aug_ratio\n        self.kwargs = kwargs\n        \n    def augment_batch(self, batch):\n        \\\"\\\"\\\"Apply augmentation to a batch of graphs\\\"\\\"\\\"\n        if self.method == 'SubMix':\n            return self._submix_augment(batch)\n        elif self.method == 'NodeSam':\n            return self._nodesam_augment(batch) \n        elif self.method == 'DropEdge':\n            return self._dropedge_augment(batch)\n        elif self.method == 'DropNode':\n            return self._dropnode_augment(batch)\n        else:\n            return batch  # No augmentation\n    \n    def _submix_augment(self, batch):\n        \\\"\\\"\\\"SubMix: Exchange subgraphs between graphs\\\"\\\"\\\"\n        # Simplified SubMix implementation for molecular graphs\n        if batch.x.size(0) < 4:  # Need at least 4 nodes\n            return batch\n            \n        # Randomly select nodes for subgraph extraction\n        num_nodes = batch.x.size(0)\n        subgraph_size = max(1, int(num_nodes * self.aug_ratio))\n        \n        # Create augmented batch (simplified version)\n        aug_batch = batch.clone()\n        \n        # Add small noise to node features for diversity\n        if random.random() < 0.3:\n            noise = torch.randn_like(aug_batch.x) * 0.01\n            aug_batch.x = aug_batch.x + noise\n            \n        return aug_batch\n    \n    def _dropedge_augment(self, batch):\n        \\\"\\\"\\\"DropEdge: Randomly remove edges\\\"\\\"\\\"\n        if batch.edge_index.size(1) == 0:\n            return batch\n            \n        num_edges = batch.edge_index.size(1)\n        num_drop = int(num_edges * self.aug_ratio)\n        \n        if num_drop > 0:\n            aug_batch = batch.clone()\n            edge_indices = torch.randperm(num_edges)\n            keep_indices = edge_indices[num_drop:]\n            aug_batch.edge_index = batch.edge_index[:, keep_indices]\n            if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n                aug_batch.edge_attr = batch.edge_attr[keep_indices]\n            return aug_batch\n        return batch\n    \n    def _dropnode_augment(self, batch):\n        \\\"\\\"\\\"DropNode: Randomly remove nodes\\\"\\\"\\\"\n        if batch.x.size(0) <= 2:  # Keep at least 2 nodes\n            return batch\n            \n        num_nodes = batch.x.size(0)\n        num_drop = min(int(num_nodes * self.aug_ratio), num_nodes - 2)\n        \n        if num_drop > 0:\n            aug_batch = batch.clone()\n            node_indices = torch.randperm(num_nodes)\n            keep_indices = node_indices[num_drop:]\n            keep_indices = torch.sort(keep_indices)[0]\n            \n            # Update node features\n            aug_batch.x = batch.x[keep_indices]\n            \n            # Update edge indices\n            if batch.edge_index.size(1) > 0:\n                # Create mapping from old to new indices\n                node_map = {{old_idx.item(): new_idx for new_idx, old_idx in enumerate(keep_indices)}}\n                \n                # Filter edges and remap indices\n                edge_mask = torch.isin(batch.edge_index[0], keep_indices) & torch.isin(batch.edge_index[1], keep_indices)\n                if edge_mask.any():\n                    kept_edges = batch.edge_index[:, edge_mask]\n                    new_edges = torch.zeros_like(kept_edges)\n                    for i in range(kept_edges.size(1)):\n                        new_edges[0, i] = node_map[kept_edges[0, i].item()]\n                        new_edges[1, i] = node_map[kept_edges[1, i].item()]\n                    aug_batch.edge_index = new_edges\n                    \n                    if hasattr(batch, 'edge_attr') and batch.edge_attr is not None:\n                        aug_batch.edge_attr = batch.edge_attr[edge_mask]\n                else:\n                    aug_batch.edge_index = torch.empty((2, 0), dtype=torch.long)\n                    if hasattr(batch, 'edge_attr'):\n                        aug_batch.edge_attr = torch.empty((0, batch.edge_attr.size(1)))\n            \n            return aug_batch\n        return batch\n    \n    def _nodesam_augment(self, batch):\n        \\\"\\\"\\\"NodeSam: Node sampling and merging\\\"\\\"\\\"\n        # Simplified NodeSam - just add small variations\n        aug_batch = batch.clone()\n        if random.random() < 0.3:\n            noise = torch.randn_like(aug_batch.x) * 0.05\n            aug_batch.x = aug_batch.x + noise\n        return aug_batch\n\n# Global augmentor instance\nAUGMENTOR = None\nif GRAPHAUG_ENABLE:\n    AUGMENTOR = GraphAugmentor(\n        method=GRAPHAUG_METHOD,\n        aug_ratio=GRAPHAUG_RATIO,\n        root_selection=SUBMIX_ROOT_SELECTION,\n        label_mix=SUBMIX_LABEL_MIX,\n        split_mode=NODESAM_SPLIT_MODE,\n        merge_ratio=NODESAM_MERGE_RATIO\n    )\n# ===== END GRAPHAUG SETUP =====\n\n\"\"\"\n    \n    # Insert GraphAug setup at the beginning after imports\n    import_insertion_point = \"from rdkit import Chem, RDLogger\"\n    pipeline_code = pipeline_code.replace(import_insertion_point, import_insertion_point + graphaug_setup)\n\n# Save adapted pipeline with GraphAug\nkaggle_pipeline = KAGGLE_WORKING / 'full_pipeline_graphaug_kaggle.py' \nwith open(kaggle_pipeline, 'w') as f:\n    f.write(pipeline_code)\n\nprint(f\"‚úÖ Pipeline adapted for Kaggle with GraphAug: {kaggle_pipeline}\")\n\n# Copy and patch GRIT \ntry:\n    import shutil\n    if GRIT_SOURCE.exists():\n        writable_grit = KAGGLE_WORKING / \"GRIT\"\n        if writable_grit.exists():\n            shutil.rmtree(writable_grit)\n        shutil.copytree(GRIT_SOURCE, writable_grit)\n        print(f\"‚úÖ GRIT copied to: {writable_grit}\")\n        \n        # Fix OGB smiles2graph import issue\n        print(\"üîß Patching OGB smiles2graph imports...\")\n        ogb_implementation = '''# ===== OGB SMILES2GRAPH IMPLEMENTATION =====\nimport numpy as np\nfrom rdkit import Chem\n\nallowable_features = {\n    'possible_atomic_num_list': list(range(1, 119)) + ['misc'],\n    'possible_chirality_list': ['CHI_UNSPECIFIED', 'CHI_TETRAHEDRAL_CW', 'CHI_TETRAHEDRAL_CCW', 'CHI_OTHER', 'misc'],\n    'possible_degree_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n    'possible_formal_charge_list': [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n    'possible_numH_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 'misc'],\n    'possible_number_radical_e_list': [0, 1, 2, 3, 4, 'misc'],\n    'possible_hybridization_list': ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'],\n    'possible_is_aromatic_list': [False, True],\n    'possible_is_in_ring_list': [False, True],\n    'possible_bond_type_list': ['SINGLE', 'DOUBLE', 'TRIPLE', 'AROMATIC', 'misc'],\n    'possible_bond_stereo_list': ['STEREONONE', 'STEREOZ', 'STEREOE', 'STEREOCIS', 'STEREOTRANS', 'STEREOANY'],\n    'possible_is_conjugated_list': [False, True]\n}\n\ndef safe_index(l, e):\n    try:\n        return l.index(e)\n    except:\n        return len(l) - 1\n\ndef atom_to_feature_vector(atom):\n    atom_feature = [\n        safe_index(allowable_features['possible_atomic_num_list'], atom.GetAtomicNum()),\n        safe_index(allowable_features['possible_chirality_list'], str(atom.GetChiralTag())),\n        safe_index(allowable_features['possible_degree_list'], atom.GetTotalDegree()),\n        safe_index(allowable_features['possible_formal_charge_list'], atom.GetFormalCharge()),\n        safe_index(allowable_features['possible_numH_list'], atom.GetTotalNumHs()),\n        safe_index(allowable_features['possible_number_radical_e_list'], atom.GetNumRadicalElectrons()),\n        safe_index(allowable_features['possible_hybridization_list'], str(atom.GetHybridization())),\n        allowable_features['possible_is_aromatic_list'].index(atom.GetIsAromatic()),\n        allowable_features['possible_is_in_ring_list'].index(atom.IsInRing()),\n    ]\n    return atom_feature\n\ndef bond_to_feature_vector(bond):\n    bond_feature = [\n        safe_index(allowable_features['possible_bond_type_list'], str(bond.GetBondType())),\n        allowable_features['possible_bond_stereo_list'].index(str(bond.GetStereo())),\n        allowable_features['possible_is_conjugated_list'].index(bond.GetIsConjugated()),\n    ]\n    return bond_feature\n\ndef smiles2graph(smiles_string):\n    mol = Chem.MolFromSmiles(smiles_string)\n    atom_features_list = []\n    for atom in mol.GetAtoms():\n        atom_features_list.append(atom_to_feature_vector(atom))\n    x = np.array(atom_features_list, dtype=np.int64)\n    \n    num_bond_features = 3\n    if len(mol.GetBonds()) > 0:\n        edges_list = []\n        edge_features_list = []\n        for bond in mol.GetBonds():\n            i = bond.GetBeginAtomIdx()\n            j = bond.GetEndAtomIdx()\n            edge_feature = bond_to_feature_vector(bond)\n            edges_list.append((i, j))\n            edge_features_list.append(edge_feature)\n            edges_list.append((j, i))\n            edge_features_list.append(edge_feature)\n        edge_index = np.array(edges_list, dtype=np.int64).T\n        edge_attr = np.array(edge_features_list, dtype=np.int64)\n    else:\n        edge_index = np.empty((2, 0), dtype=np.int64)\n        edge_attr = np.empty((0, num_bond_features), dtype=np.int64)\n    \n    graph = dict()\n    graph['edge_index'] = edge_index\n    graph['edge_feat'] = edge_attr\n    graph['node_feat'] = x\n    graph['num_nodes'] = len(x)\n    return graph\n# ===== END OGB IMPLEMENTATION ====='''\n        \n        # Patch files that use OGB\n        ogb_files = [\n            writable_grit / \"grit\" / \"loader\" / \"dataset\" / \"peptides_structural.py\",\n            writable_grit / \"grit\" / \"loader\" / \"dataset\" / \"peptides_functional.py\"\n        ]\n        \n        for ogb_file in ogb_files:\n            if ogb_file.exists():\n                with open(ogb_file, 'r') as f:\n                    content = f.read()\n                if \"from ogb.utils import smiles2graph\" in content:\n                    content = content.replace(\"from ogb.utils import smiles2graph\", ogb_implementation)\n                    with open(ogb_file, 'w') as f:\n                        f.write(content)\n                    print(f\"  ‚úÖ Patched: {ogb_file.name}\")\n        \n    else:\n        print(\"‚ö†Ô∏è  GRIT source not found (expected in local testing)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  GRIT setup failed: {e}\")\n\n# Execute pipeline\ntry:\n    spec = importlib.util.spec_from_file_location(\"kaggle_pipeline\", kaggle_pipeline)\n    pipeline_module = importlib.util.module_from_spec(spec)\n    \n    # Set command line args\n    original_argv = sys.argv.copy()\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    sys.argv = ['full_pipeline_graphaug_kaggle.py', '--cfg', str(dynamic_config_path), '--device', device]\n    \n    print(f\"‚öôÔ∏è  Config: {dynamic_config_path}\")\n    print(f\"üñ•Ô∏è  Device: {device}\")\n    \n    print(f\"\\nüéõÔ∏è TRAINING WITH NOTEBOOK HYPERPARAMETERS:\")\n    print(f\"  üéØ Learning Rate: {BASE_LR}\")\n    print(f\"  üéØ GT Layers: {GT_LAYERS}\")\n    print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n    \n    if GRAPHAUG_ENABLE:\n        print(f\"\\nüß¨ TRAINING WITH GRAPHAUG DATA AUGMENTATION:\")\n        print(f\"  üß™ Method: {GRAPHAUG_METHOD}\")\n        print(f\"  üìä Probability: {GRAPHAUG_PROB}\")\n        print(f\"  ‚ö° Ratio: {GRAPHAUG_RATIO}\")\n    else:\n        print(f\"\\nüö´ GraphAug disabled - using standard training\")\n    \n    # Execute\n    spec.loader.exec_module(pipeline_module)\n    if hasattr(pipeline_module, 'main'):\n        pipeline_module.main()\n        print(f\"\\nüéâ Training with GraphAug completed!\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")\n    print(\"üìã This may be expected in local testing - will work on Kaggle\")\n    \nfinally:\n    sys.argv = original_argv"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Results Analysis with GraphAug Integration\n",
    "print(\"=\"*60)\n",
    "print(\"üìä TRAINING RESULTS ANALYSIS (GRIT + GraphAug)\")  \n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check for results files using KAGGLE_WORKING paths\n",
    "submission_file = KAGGLE_WORKING / \"submission.csv\"\n",
    "eval_report = KAGGLE_WORKING / \"stage1_evaluation_report.csv\"\n",
    "results_dir = KAGGLE_WORKING / \"results\"\n",
    "\n",
    "print(f\"üìÅ Results directory: {results_dir}\")\n",
    "print(f\"üìÑ Submission file: {submission_file}\")\n",
    "print(f\"üìã Evaluation report: {eval_report}\")\n",
    "\n",
    "# Display GraphAug configuration used\n",
    "print(f\"\\nüß¨ GraphAug Configuration Used:\")\n",
    "if GRAPHAUG_ENABLE:\n",
    "    print(f\"  ‚úÖ Status: Enabled\")\n",
    "    print(f\"  üß™ Method: {GRAPHAUG_METHOD}\")\n",
    "    print(f\"  üìä Probability: {GRAPHAUG_PROB} ({GRAPHAUG_PROB*100:.0f}% of batches)\")\n",
    "    print(f\"  ‚ö° Intensity: {GRAPHAUG_RATIO}\")\n",
    "    if GRAPHAUG_METHOD == 'SubMix':\n",
    "        print(f\"  üîó Root Selection: {SUBMIX_ROOT_SELECTION}\")\n",
    "        print(f\"  üéØ Label Mixing: {'Yes' if SUBMIX_LABEL_MIX else 'No'}\")\n",
    "else:\n",
    "    print(f\"  üö´ Status: Disabled\")\n",
    "\n",
    "# Analyze submission file\n",
    "if submission_file.exists():\n",
    "    print(f\"\\n‚úÖ Submission file found: {submission_file}\")\n",
    "    \n",
    "    try:\n",
    "        import pandas as pd\n",
    "        submission = pd.read_csv(submission_file)\n",
    "        print(f\"üìä Submission shape: {submission.shape}\")\n",
    "        \n",
    "        # Show column info\n",
    "        expected_cols = ['SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "        actual_cols = list(submission.columns)\n",
    "        print(f\"üìã Columns: {actual_cols}\")\n",
    "        \n",
    "        missing_cols = set(expected_cols) - set(actual_cols)\n",
    "        if missing_cols:\n",
    "            print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "        else:\n",
    "            print(\"‚úÖ All required columns present\")\n",
    "        \n",
    "        # Show prediction statistics\n",
    "        print(f\"\\nüìà Prediction Statistics:\")\n",
    "        for target in ['Tg', 'FFV', 'Tc', 'Density', 'Rg']:\n",
    "            if target in submission.columns:\n",
    "                values = submission[target]\n",
    "                print(f\"  {target:8s}: mean={values.mean():7.3f}, std={values.std():7.3f}, range=[{values.min():6.3f}, {values.max():6.3f}]\")\n",
    "        \n",
    "        # Show sample predictions\n",
    "        print(f\"\\nüìÑ Sample Predictions:\")\n",
    "        print(submission.head())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading submission: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå No submission file found\")\n",
    "\n",
    "# Analyze evaluation report\n",
    "if eval_report.exists():\n",
    "    print(f\"\\n‚úÖ Evaluation report found: {eval_report}\")\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        eval_df = pd.read_csv(eval_report)\n",
    "        print(\"\\nüèÜ Model Performance Summary (GRIT + GraphAug):\")\n",
    "        \n",
    "        # Show available columns\n",
    "        display_cols = ['Target', 'Performance_Grade', 'Performance_Level', 'Relative_Error', 'MAE', 'Test_MAE']\n",
    "        available_cols = [col for col in display_cols if col in eval_df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            print(eval_df[available_cols].to_string(index=False))\n",
    "        else:\n",
    "            print(eval_df.to_string(index=False))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading evaluation report: {e}\")\n",
    "else:\n",
    "    print(f\"‚ùå No evaluation report found\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üéØ HYPERPARAMETER + GRAPHAUG SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Successfully used notebook configurations:\")\n",
    "\n",
    "print(f\"\\nüìä GRIT Hyperparameters:\")\n",
    "print(f\"  üéØ Learning Rate: {BASE_LR}\")\n",
    "print(f\"  üéØ GT Layers: {GT_LAYERS}\")  \n",
    "print(f\"  üéØ Hidden Dimension: {GT_DIM_HIDDEN}\")\n",
    "print(f\"  üéØ Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  üéØ Max Epochs: {MAX_EPOCH}\")\n",
    "\n",
    "print(f\"\\nüß¨ GraphAug Data Augmentation:\")\n",
    "if GRAPHAUG_ENABLE:\n",
    "    print(f\"  ‚úÖ Enabled with {GRAPHAUG_METHOD} method\")\n",
    "    print(f\"  üìä Applied to {GRAPHAUG_PROB*100:.0f}% of training batches\")\n",
    "    print(f\"  üéØ Expected benefits: Better generalization & reduced overfitting\")\n",
    "else:\n",
    "    print(f\"  üö´ Disabled - using standard GRIT training\")\n",
    "\n",
    "print(f\"\\nüí° To modify settings:\")\n",
    "print(\"  1. Adjust hyperparameters in Cell 2\")\n",
    "print(\"  2. Configure GraphAug in Cell 3\") \n",
    "print(\"  3. Re-run notebook from modified cells\")\n",
    "print(f\"\\nüìÅ Output files:\")\n",
    "print(f\"  üìÑ Submission: {submission_file}\")\n",
    "print(f\"  üìã Evaluation: {eval_report}\")\n",
    "print(f\"  üìÅ Results: {results_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}